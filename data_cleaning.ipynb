{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Reports 01 February 2024 - 01 February 2024.csv\n",
      "Product Reports 29 December 2023 - 29 December 2023.csv\n",
      "Product Reports 06 July 2023 - 06 July 2023.csv\n",
      "Product Reports 18 October 2022 - 18 October 2022.csv\n",
      "Product Reports 25 November 2023 - 25 November 2023.csv\n",
      "Product Reports 10 January 2024 - 10 January 2024.csv\n",
      "Product Reports 15 March 2024 - 15 March 2024.csv\n",
      "Product Reports 22 January 2022 - 22 January 2022.csv\n",
      "Product Reports 24 January 2023 - 24 January 2023.csv\n",
      "Product Reports 07 July 2023 - 07 July 2023.csv\n",
      "Product Reports 10 October 2022 - 10 October 2022.csv\n",
      "Product Reports 13 February 2022 - 13 February 2022.csv\n",
      "Product Reports 16 October 2023 - 16 October 2023.csv\n",
      "Product Reports 06 November 2022 - 06 November 2022.csv\n",
      "Product Reports 29 August 2023 - 29 August 2023.csv\n",
      "Product Reports 26 August 2022 - 26 August 2022.csv\n",
      "Product Reports 20 May 2022 - 20 May 2022.csv\n",
      "Product Reports 11 December 2022 - 11 December 2022.csv\n",
      "Product Reports 23 August 2023 - 23 August 2023.csv\n",
      "Product Reports 08 February 2022 - 08 February 2022.csv\n",
      "Product Reports 18 January 2024 - 18 January 2024.csv\n",
      "Product Reports 28 May 2022 - 28 May 2022.csv\n",
      "Product Reports 06 May 2022 - 06 May 2022.csv\n",
      "Product Reports 04 May 2023 - 04 May 2023.csv\n",
      "Product Reports 17 October 2023 - 17 October 2023.csv\n",
      "Product Reports 11 October 2022 - 11 October 2022.csv\n",
      "Product Reports 28 December 2023 - 28 December 2023.csv\n",
      "Product Reports 11 September 2022 - 11 September 2022.csv\n",
      "Product Reports 19 January 2024 - 19 January 2024.csv\n",
      "Product Reports 23 September 2022 - 23 September 2022.csv\n",
      "Product Reports 24 November 2023 - 24 November 2023.csv\n",
      "Product Reports 19 October 2022 - 19 October 2022.csv\n",
      "Product Reports 10 December 2022 - 10 December 2022.csv\n",
      "Product Reports 09 February 2022 - 09 February 2022.csv\n",
      "Product Reports 25 January 2023 - 25 January 2023.csv\n",
      "Product Reports 23 January 2022 - 23 January 2022.csv\n",
      "Product Reports 11 January 2024 - 11 January 2024.csv\n",
      "Product Reports 07 November 2022 - 07 November 2022.csv\n",
      "Product Reports 12 February 2022 - 12 February 2022.csv\n",
      "Product Reports 15 October 2023 - 15 October 2023.csv\n",
      "Product Reports 13 October 2022 - 13 October 2022.csv\n",
      "Product Reports 31 July 2023 - 31 July 2023.csv\n",
      "Product Reports 12 November 2022 - 12 November 2022.csv\n",
      "Product Reports 31 August 2023 - 31 August 2023.csv\n",
      "Product Reports 21 March 2023 - 21 March 2023.csv\n",
      "Product Reports 07 February 2022 - 07 February 2022.csv\n",
      "Product Reports 20 April 2023 - 20 April 2023.csv\n",
      "Product Reports 29 January 2022 - 29 January 2022.csv\n",
      "Product Reports 05 December 2022 - 05 December 2022.csv\n",
      "Product Reports 01 April 2022 - 01 April 2022.csv\n",
      "Product Reports 30 July 2023 - 30 July 2023.csv\n",
      "Product Reports 09 November 2022 - 09 November 2022.csv\n",
      "Product Reports 22 September 2022 - 22 September 2022.csv\n",
      "Product Reports 15 February 2024 - 15 February 2024.csv\n",
      "Product Reports 21 March 2022 - 21 March 2022.csv\n",
      "Product Reports 24 February 2023 - 24 February 2023.csv\n",
      "Product Reports 19 July 2023 - 19 July 2023.csv\n",
      "Product Reports 10 September 2022 - 10 September 2022.csv\n",
      "Product Reports 25 May 2022 - 25 May 2022.csv\n",
      "Product Reports 01 April 2023 - 01 April 2023.csv\n",
      "Product Reports 18 July 2023 - 18 July 2023.csv\n",
      "Product Reports 09 May 2023 - 09 May 2023.csv\n",
      "Product Reports 20 April 2022 - 20 April 2022.csv\n",
      "Product Reports 26 December 2023 - 26 December 2023.csv\n",
      "Product Reports 13 January 2024 - 13 January 2024.csv\n",
      "Product Reports 27 January 2023 - 27 January 2023.csv\n",
      "Product Reports 21 January 2022 - 21 January 2022.csv\n",
      "Product Reports 01 May 2023 - 01 May 2023.csv\n",
      "Product Reports 04 December 2022 - 04 December 2022.csv\n",
      "Product Reports 03 May 2022 - 03 May 2022.csv\n",
      "Product Reports 08 November 2022 - 08 November 2022.csv\n",
      "Product Reports 24 August 2022 - 24 August 2022.csv\n",
      "Product Reports 15 March 2022 - 15 March 2022.csv\n",
      "Product Reports 21 August 2023 - 21 August 2023.csv\n",
      "Product Reports 14 April 2022 - 14 April 2022.csv\n",
      "Product Reports 20 January 2022 - 20 January 2022.csv\n",
      "Product Reports 06 February 2022 - 06 February 2022.csv\n",
      "Product Reports 26 January 2023 - 26 January 2023.csv\n",
      "Product Reports 12 January 2024 - 12 January 2024.csv\n",
      "Product Reports 13 November 2022 - 13 November 2022.csv\n",
      "Product Reports 27 December 2023 - 27 December 2023.csv\n",
      "Product Reports 12 October 2022 - 12 October 2022.csv\n",
      "Product Reports 14 October 2023 - 14 October 2023.csv\n",
      "Product Reports 15 March 2023 - 15 March 2023.csv\n",
      "Product Reports 14 February 2024 - 14 February 2024.csv\n",
      "Product Reports 28 January 2022 - 28 January 2022.csv\n",
      "Product Reports 14 April 2023 - 14 April 2023.csv\n",
      "Product Reports 30 November 2023 - 30 November 2023.csv\n",
      "Product Reports 01 September 2022 - 01 September 2022.csv\n",
      "Product Reports 25 February 2023 - 25 February 2023.csv\n",
      "Product Reports 03 September 2022 - 03 September 2022.csv\n",
      "Product Reports 25 February 2024 - 25 February 2024.csv\n",
      "Product Reports 14 February 2023 - 14 February 2023.csv\n",
      "Product Reports 12 August 2022 - 12 August 2022.csv\n",
      "Product Reports 17 August 2023 - 17 August 2023.csv\n",
      "Product Reports 13 March 2024 - 13 March 2024.csv\n",
      "Product Reports 01 November 2023 - 01 November 2023.csv\n",
      "Product Reports 24 June 2022 - 24 June 2022.csv\n",
      "Product Reports 18 August 2022 - 18 August 2022.csv\n",
      "Product Reports 05 January 2024 - 05 January 2024.csv\n",
      "Product Reports 16 December 2023 - 16 December 2023.csv\n",
      "Product Reports 31 January 2023 - 31 January 2023.csv\n",
      "Product Reports 25 June 2022 - 25 June 2022.csv\n",
      "Product Reports 27 June 2022 - 27 June 2022.csv\n",
      "Product Reports 03 October 2023 - 03 October 2023.csv\n",
      "Product Reports 22 November 2022 - 22 November 2022.csv\n",
      "Product Reports 05 October 2022 - 05 October 2022.csv\n",
      "Product Reports 06 May 2023 - 06 May 2023.csv\n",
      "Product Reports 04 May 2022 - 04 May 2022.csv\n",
      "Product Reports 26 June 2022 - 26 June 2022.csv\n",
      "Product Reports 17 December 2023 - 17 December 2023.csv\n",
      "Product Reports 19 April 2023 - 19 April 2023.csv\n",
      "Product Reports 26 July 2022 - 26 July 2022.csv\n",
      "Product Reports 22 May 2022 - 22 May 2022.csv\n",
      "Product Reports 08 August 2022 - 08 August 2022.csv\n",
      "Product Reports 02 August 2022 - 02 August 2022.csv\n",
      "Product Reports 04 October 2022 - 04 October 2022.csv\n",
      "Product Reports 06 March 2024 - 06 March 2024.csv\n",
      "Product Reports 02 October 2023 - 02 October 2023.csv\n",
      "Product Reports 07 August 2023 - 07 August 2023.csv\n",
      "Product Reports 24 February 2024 - 24 February 2024.csv\n",
      "Product Reports 27 July 2022 - 27 July 2022.csv\n",
      "Product Reports 12 September 2022 - 12 September 2022.csv\n",
      "Product Reports 20 September 2022 - 20 September 2022.csv\n",
      "Product Reports 15 February 2023 - 15 February 2023.csv\n",
      "Product Reports 18 March 2023 - 18 March 2023.csv\n",
      "Product Reports 25 July 2022 - 25 July 2022.csv\n",
      "Product Reports 19 April 2022 - 19 April 2022.csv\n",
      "Product Reports 30 January 2023 - 30 January 2023.csv\n",
      "Product Reports 04 January 2024 - 04 January 2024.csv\n",
      "Product Reports 24 July 2022 - 24 July 2022.csv\n",
      "Product Reports 18 March 2022 - 18 March 2022.csv\n",
      "Product Reports 23 November 2022 - 23 November 2022.csv\n",
      "Product Reports 06 October 2022 - 06 October 2022.csv\n",
      "Product Reports 26 April 2023 - 26 April 2023.csv\n",
      "Product Reports 23 February 2022 - 23 February 2022.csv\n",
      "Product Reports 13 June 2022 - 13 June 2022.csv\n",
      "Product Reports 07 April 2022 - 07 April 2022.csv\n",
      "Product Reports 06 March 2022 - 06 March 2022.csv\n",
      "Product Reports 12 June 2022 - 12 June 2022.csv\n",
      "Product Reports 27 March 2023 - 27 March 2023.csv\n",
      "Product Reports 21 December 2022 - 21 December 2022.csv\n",
      "Product Reports 21 September 2022 - 21 September 2022.csv\n",
      "Product Reports 10 June 2022 - 10 June 2022.csv\n",
      "Product Reports 19 December 2023 - 19 December 2023.csv\n",
      "Product Reports 07 April 2023 - 07 April 2023.csv\n",
      "Product Reports 15 November 2023 - 15 November 2023.csv\n",
      "Product Reports 08 October 2023 - 08 October 2023.csv\n",
      "Product Reports 26 April 2022 - 26 April 2022.csv\n",
      "Product Reports 13 September 2022 - 13 September 2022.csv\n",
      "Product Reports 27 March 2022 - 27 March 2022.csv\n",
      "Product Reports 02 December 2023 - 02 December 2023.csv\n",
      "Product Reports 06 March 2023 - 06 March 2023.csv\n",
      "Product Reports 05 August 2023 - 05 August 2023.csv\n",
      "Product Reports 06 January 2024 - 06 January 2024.csv\n",
      "Product Reports 01 May 2022 - 01 May 2022.csv\n",
      "Product Reports 11 June 2022 - 11 June 2022.csv\n",
      "Product Reports 03 May 2023 - 03 May 2023.csv\n",
      "Product Reports 20 December 2022 - 20 December 2022.csv\n",
      "Product Reports 12 April 2022 - 12 April 2022.csv\n",
      "Product Reports 09 October 2023 - 09 October 2023.csv\n",
      "Product Reports 09 May 2022 - 09 May 2022.csv\n",
      "Product Reports 11 July 2022 - 11 July 2022.csv\n",
      "Product Reports 27 May 2022 - 27 May 2022.csv\n",
      "Product Reports 13 March 2022 - 13 March 2022.csv\n",
      "Product Reports 10 July 2022 - 10 July 2022.csv\n",
      "Product Reports 07 January 2024 - 07 January 2024.csv\n",
      "Product Reports 22 February 2022 - 22 February 2022.csv\n",
      "Product Reports 01 October 2023 - 01 October 2023.csv\n",
      "Product Reports 03 December 2023 - 03 December 2023.csv\n",
      "Product Reports 07 October 2022 - 07 October 2022.csv\n",
      "Product Reports 12 July 2022 - 12 July 2022.csv\n",
      "Product Reports 12 April 2023 - 12 April 2023.csv\n",
      "Product Reports 10 August 2022 - 10 August 2022.csv\n",
      "Product Reports 18 December 2023 - 18 December 2023.csv\n",
      "Product Reports 30 September 2022 - 30 September 2022.csv\n",
      "Product Reports 13 March 2023 - 13 March 2023.csv\n",
      "Product Reports 15 August 2023 - 15 August 2023.csv\n",
      "Product Reports 01 February 2023 - 01 February 2023.csv\n",
      "Product Reports 14 November 2023 - 14 November 2023.csv\n",
      "Product Reports 02 September 2022 - 02 September 2022.csv\n",
      "Product Reports 13 July 2022 - 13 July 2022.csv\n",
      "Product Reports 21 December 2023 - 21 December 2023.csv\n",
      "Product Reports 09 February 2024 - 09 February 2024.csv\n",
      "Product Reports 20 January 2024 - 20 January 2024.csv\n",
      "Product Reports 06 April 2022 - 06 April 2022.csv\n",
      "Product Reports 21 August 2022 - 21 August 2022.csv\n",
      "Product Reports 24 August 2023 - 24 August 2023.csv\n",
      "Product Reports 12 January 2022 - 12 January 2022.csv\n",
      "Product Reports 27 April 2023 - 27 April 2023.csv\n",
      "Product Reports 14 January 2023 - 14 January 2023.csv\n",
      "Product Reports 06 September 2022 - 06 September 2022.csv\n",
      "Product Reports 26 March 2023 - 26 March 2023.csv\n",
      "Product Reports 12 February 2024 - 12 February 2024.csv\n",
      "Product Reports 07 March 2022 - 07 March 2022.csv\n",
      "Product Reports 23 February 2023 - 23 February 2023.csv\n",
      "Product Reports 28 October 2022 - 28 October 2022.csv\n",
      "Product Reports 02 December 2022 - 02 December 2022.csv\n",
      "Product Reports 28 January 2024 - 28 January 2024.csv\n",
      "Product Reports 27 April 2022 - 27 April 2022.csv\n",
      "Product Reports 06 April 2023 - 06 April 2023.csv\n",
      "Product Reports 20 October 2022 - 20 October 2022.csv\n",
      "Product Reports 07 March 2023 - 07 March 2023.csv\n",
      "Product Reports 26 October 2023 - 26 October 2023.csv\n",
      "Product Reports 19 December 2022 - 19 December 2022.csv\n",
      "Product Reports 26 March 2022 - 26 March 2022.csv\n",
      "Product Reports 29 May 2022 - 29 May 2022.csv\n",
      "Product Reports 19 September 2023 - 19 September 2023.csv\n",
      "Product Reports 07 May 2022 - 07 May 2022.csv\n",
      "Product Reports 05 May 2023 - 05 May 2023.csv\n",
      "Product Reports 15 November 2022 - 15 November 2022.csv\n",
      "Product Reports 29 January 2024 - 29 January 2024.csv\n",
      "Product Reports 13 February 2024 - 13 February 2024.csv\n",
      "Product Reports 22 February 2023 - 22 February 2023.csv\n",
      "Product Reports 31 August 2022 - 31 August 2022.csv\n",
      "Product Reports 21 May 2022 - 21 May 2022.csv\n",
      "Product Reports 13 April 2022 - 13 April 2022.csv\n",
      "Product Reports 25 September 2022 - 25 September 2022.csv\n",
      "Product Reports 08 February 2024 - 08 February 2024.csv\n",
      "Product Reports 12 March 2022 - 12 March 2022.csv\n",
      "Product Reports 27 October 2023 - 27 October 2023.csv\n",
      "Product Reports 20 December 2023 - 20 December 2023.csv\n",
      "Product Reports 21 October 2022 - 21 October 2022.csv\n",
      "Product Reports 17 September 2022 - 17 September 2022.csv\n",
      "Product Reports 18 December 2022 - 18 December 2022.csv\n",
      "Product Reports 15 January 2023 - 15 January 2023.csv\n",
      "Product Reports 13 January 2022 - 13 January 2022.csv\n",
      "Product Reports 08 September 2023 - 08 September 2023.csv\n",
      "Product Reports 13 April 2023 - 13 April 2023.csv\n",
      "Product Reports 14 November 2022 - 14 November 2022.csv\n",
      "Product Reports 21 January 2024 - 21 January 2024.csv\n",
      "Product Reports 01 February 2022 - 01 February 2022.csv\n",
      "Product Reports 03 December 2022 - 03 December 2022.csv\n",
      "Product Reports 12 March 2023 - 12 March 2023.csv\n",
      "Product Reports 29 October 2022 - 29 October 2022.csv\n",
      "Product Reports 16 December 2022 - 16 December 2022.csv\n",
      "Product Reports 01 June 2022 - 01 June 2022.csv\n",
      "Product Reports 19 January 2022 - 19 January 2022.csv\n",
      "Product Reports 12 March 2024 - 12 March 2024.csv\n",
      "Product Reports 09 September 2023 - 09 September 2023.csv\n",
      "Product Reports 25 October 2023 - 25 October 2023.csv\n",
      "Product Reports 23 October 2022 - 23 October 2022.csv\n",
      "Product Reports 01 November 2022 - 01 November 2022.csv\n",
      "Product Reports 14 February 2022 - 14 February 2022.csv\n",
      "Product Reports 23 January 2024 - 23 January 2024.csv\n",
      "Product Reports 16 September 2022 - 16 September 2022.csv\n",
      "Product Reports 17 January 2023 - 17 January 2023.csv\n",
      "Product Reports 11 January 2022 - 11 January 2022.csv\n",
      "Product Reports 02 June 2022 - 02 June 2022.csv\n",
      "Product Reports 24 September 2022 - 24 September 2022.csv\n",
      "Product Reports 29 June 2022 - 29 June 2022.csv\n",
      "Product Reports 28 June 2022 - 28 June 2022.csv\n",
      "Product Reports 03 June 2022 - 03 June 2022.csv\n",
      "Product Reports 06 February 2024 - 06 February 2024.csv\n",
      "Product Reports 22 November 2023 - 22 November 2023.csv\n",
      "Product Reports 02 May 2022 - 02 May 2022.csv\n",
      "Product Reports 03 July 2022 - 03 July 2022.csv\n",
      "Product Reports 10 January 2022 - 10 January 2022.csv\n",
      "Product Reports 28 July 2022 - 28 July 2022.csv\n",
      "Product Reports 16 January 2023 - 16 January 2023.csv\n",
      "Product Reports 22 January 2024 - 22 January 2024.csv\n",
      "Product Reports 18 April 2023 - 18 April 2023.csv\n",
      "Product Reports 18 September 2023 - 18 September 2023.csv\n",
      "Product Reports 24 May 2022 - 24 May 2022.csv\n",
      "Product Reports 07 March 2024 - 07 March 2024.csv\n",
      "Product Reports 15 February 2022 - 15 February 2022.csv\n",
      "Product Reports 08 May 2023 - 08 May 2023.csv\n",
      "Product Reports 17 December 2022 - 17 December 2022.csv\n",
      "Product Reports 29 July 2022 - 29 July 2022.csv\n",
      "Product Reports 02 July 2022 - 02 July 2022.csv\n",
      "Product Reports 19 March 2023 - 19 March 2023.csv\n",
      "Product Reports 07 February 2024 - 07 February 2024.csv\n",
      "Product Reports 18 April 2022 - 18 April 2022.csv\n",
      "Product Reports 23 November 2023 - 23 November 2023.csv\n",
      "Product Reports 18 January 2022 - 18 January 2022.csv\n",
      "Product Reports 23 August 2022 - 23 August 2022.csv\n",
      "Product Reports 01 July 2022 - 01 July 2022.csv\n",
      "Product Reports 07 September 2022 - 07 September 2022.csv\n",
      "Product Reports 26 August 2023 - 26 August 2023.csv\n",
      "Product Reports 29 August 2022 - 29 August 2022.csv\n",
      "Product Reports 22 October 2022 - 22 October 2022.csv\n",
      "Product Reports 24 October 2023 - 24 October 2023.csv\n",
      "Product Reports 19 March 2022 - 19 March 2022.csv\n",
      "Product Reports 05 December 2023 - 05 December 2023.csv\n",
      "Product Reports 09 November 2023 - 09 November 2023.csv\n",
      "Product Reports 20 March 2023 - 20 March 2023.csv\n",
      "Product Reports 14 July 2023 - 14 July 2023.csv\n",
      "Product Reports 05 September 2022 - 05 September 2022.csv\n",
      "Product Reports 01 January 2023 - 01 January 2023.csv\n",
      "Product Reports 01 March 2022 - 01 March 2022.csv\n",
      "Product Reports 07 January 2022 - 07 January 2022.csv\n",
      "Product Reports 15 July 2023 - 15 July 2023.csv\n",
      "Product Reports 21 April 2023 - 21 April 2023.csv\n",
      "Product Reports 07 February 2023 - 07 February 2023.csv\n",
      "Product Reports 12 November 2023 - 12 November 2023.csv\n",
      "Product Reports 17 July 2023 - 17 July 2023.csv\n",
      "Product Reports 26 December 2022 - 26 December 2022.csv\n",
      "Product Reports 09 January 2023 - 09 January 2023.csv\n",
      "Product Reports 01 March 2023 - 01 March 2023.csv\n",
      "Product Reports 20 March 2022 - 20 March 2022.csv\n",
      "Product Reports 28 September 2023 - 28 September 2023.csv\n",
      "Product Reports 21 April 2022 - 21 April 2022.csv\n",
      "Product Reports 23 May 2022 - 23 May 2022.csv\n",
      "Product Reports 15 August 2022 - 15 August 2022.csv\n",
      "Product Reports 10 August 2023 - 10 August 2023.csv\n",
      "Product Reports 16 July 2023 - 16 July 2023.csv\n",
      "Product Reports 24 February 2022 - 24 February 2022.csv\n",
      "Product Reports 07 May 2023 - 07 May 2023.csv\n",
      "Product Reports 08 January 2023 - 08 January 2023.csv\n",
      "Product Reports 05 May 2022 - 05 May 2022.csv\n",
      "Product Reports 13 November 2023 - 13 November 2023.csv\n",
      "Product Reports 14 March 2022 - 14 March 2022.csv\n",
      "Product Reports 06 February 2023 - 06 February 2023.csv\n",
      "Product Reports 04 December 2023 - 04 December 2023.csv\n",
      "Product Reports 26 September 2022 - 26 September 2022.csv\n",
      "Product Reports 15 April 2022 - 15 April 2022.csv\n",
      "Product Reports 14 September 2022 - 14 September 2022.csv\n",
      "Product Reports 08 November 2023 - 08 November 2023.csv\n",
      "Product Reports 06 January 2022 - 06 January 2022.csv\n",
      "Product Reports 25 February 2022 - 25 February 2022.csv\n",
      "Product Reports 14 March 2023 - 14 March 2023.csv\n",
      "Product Reports 30 November 2022 - 30 November 2022.csv\n",
      "Product Reports 05 August 2022 - 05 August 2022.csv\n",
      "Product Reports 15 April 2023 - 15 April 2023.csv\n",
      "Product Reports 27 December 2022 - 27 December 2022.csv\n",
      "Product Reports 07 August 2022 - 07 August 2022.csv\n",
      "Product Reports 02 August 2023 - 02 August 2023.csv\n",
      "Product Reports 08 August 2023 - 08 August 2023.csv\n",
      "Product Reports 08 July 2023 - 08 July 2023.csv\n",
      "Product Reports 23 July 2023 - 23 July 2023.csv\n",
      "Product Reports 29 December 2022 - 29 December 2022.csv\n",
      "Product Reports 09 July 2023 - 09 July 2023.csv\n",
      "Product Reports 14 March 2024 - 14 March 2024.csv\n",
      "Product Reports 30 October 2023 - 30 October 2023.csv\n",
      "Product Reports 25 November 2022 - 25 November 2022.csv\n",
      "Product Reports 11 December 2023 - 11 December 2023.csv\n",
      "Product Reports 20 July 2023 - 20 July 2023.csv\n",
      "Product Reports 04 January 2022 - 04 January 2022.csv\n",
      "Product Reports 15 September 2022 - 15 September 2022.csv\n",
      "Product Reports 02 January 2023 - 02 January 2023.csv\n",
      "Product Reports 27 September 2022 - 27 September 2022.csv\n",
      "Product Reports 08 February 2023 - 08 February 2023.csv\n",
      "Product Reports 22 February 2024 - 22 February 2024.csv\n",
      "Product Reports 08 May 2022 - 08 May 2022.csv\n",
      "Product Reports 26 May 2022 - 26 May 2022.csv\n",
      "Product Reports 06 November 2023 - 06 November 2023.csv\n",
      "Product Reports 21 July 2023 - 21 July 2023.csv\n",
      "Product Reports 13 February 2023 - 13 February 2023.csv\n",
      "Product Reports 03 January 2023 - 03 January 2023.csv\n",
      "Product Reports 05 January 2022 - 05 January 2022.csv\n",
      "Product Reports 28 December 2022 - 28 December 2022.csv\n",
      "Product Reports 02 May 2023 - 02 May 2023.csv\n",
      "Product Reports 18 August 2023 - 18 August 2023.csv\n",
      "Product Reports 24 November 2022 - 24 November 2022.csv\n",
      "Product Reports 17 August 2022 - 17 August 2022.csv\n",
      "Product Reports 29 September 2023 - 29 September 2023.csv\n",
      "Product Reports 12 August 2023 - 12 August 2023.csv\n",
      "Product Reports 01 March 2024 - 01 March 2024.csv\n",
      "Product Reports 23 February 2024 - 23 February 2024.csv\n",
      "Product Reports 12 February 2023 - 12 February 2023.csv\n",
      "Product Reports 07 November 2023 - 07 November 2023.csv\n",
      "Product Reports 10 December 2023 - 10 December 2023.csv\n",
      "Product Reports 04 September 2022 - 04 September 2022.csv\n",
      "Product Reports 09 February 2023 - 09 February 2023.csv\n",
      "Product Reports 31 October 2023 - 31 October 2023.csv\n",
      "Product Reports 22 March 2023 - 22 March 2023.csv\n",
      "Product Reports 20 January 2023 - 20 January 2023.csv\n",
      "Product Reports 26 January 2022 - 26 January 2022.csv\n",
      "Product Reports 03 March 2022 - 03 March 2022.csv\n",
      "Product Reports 14 January 2024 - 14 January 2024.csv\n",
      "Product Reports 16 July 2022 - 16 July 2022.csv\n",
      "Product Reports 20 November 2022 - 20 November 2022.csv\n",
      "Product Reports 17 July 2022 - 17 July 2022.csv\n",
      "Product Reports 02 April 2022 - 02 April 2022.csv\n",
      "Product Reports 23 April 2023 - 23 April 2023.csv\n",
      "Product Reports 27 February 2024 - 27 February 2024.csv\n",
      "Product Reports 03 March 2023 - 03 March 2023.csv\n",
      "Product Reports 15 July 2022 - 15 July 2022.csv\n",
      "Product Reports 13 September 2023 - 13 September 2023.csv\n",
      "Product Reports 22 March 2022 - 22 March 2022.csv\n",
      "Product Reports 03 November 2023 - 03 November 2023.csv\n",
      "Product Reports 21 September 2023 - 21 September 2023.csv\n",
      "Product Reports 16 February 2023 - 16 February 2023.csv\n",
      "Product Reports 28 January 2023 - 28 January 2023.csv\n",
      "Product Reports 14 December 2023 - 14 December 2023.csv\n",
      "Product Reports 19 May 2022 - 19 May 2022.csv\n",
      "Product Reports 23 April 2022 - 23 April 2022.csv\n",
      "Product Reports 14 July 2022 - 14 July 2022.csv\n",
      "Product Reports 12 October 2023 - 12 October 2023.csv\n",
      "Product Reports 18 November 2023 - 18 November 2023.csv\n",
      "Product Reports 02 April 2023 - 02 April 2023.csv\n",
      "Product Reports 14 October 2022 - 14 October 2022.csv\n",
      "Product Reports 11 May 2022 - 11 May 2022.csv\n",
      "Product Reports 16 March 2022 - 16 March 2022.csv\n",
      "Product Reports 27 August 2023 - 27 August 2023.csv\n",
      "Product Reports 29 January 2023 - 29 January 2023.csv\n",
      "Product Reports 22 August 2022 - 22 August 2022.csv\n",
      "Product Reports 28 August 2022 - 28 August 2022.csv\n",
      "Product Reports 14 June 2022 - 14 June 2022.csv\n",
      "Product Reports 15 June 2022 - 15 June 2022.csv\n",
      "Product Reports 15 October 2022 - 15 October 2022.csv\n",
      "Product Reports 13 October 2023 - 13 October 2023.csv\n",
      "Product Reports 21 November 2022 - 21 November 2022.csv\n",
      "Product Reports 17 April 2022 - 17 April 2022.csv\n",
      "Product Reports 15 January 2024 - 15 January 2024.csv\n",
      "Product Reports 15 December 2023 - 15 December 2023.csv\n",
      "Product Reports 27 January 2022 - 27 January 2022.csv\n",
      "Product Reports 16 March 2023 - 16 March 2023.csv\n",
      "Product Reports 17 June 2022 - 17 June 2022.csv\n",
      "Product Reports 21 January 2023 - 21 January 2023.csv\n",
      "Product Reports 19 November 2023 - 19 November 2023.csv\n",
      "Product Reports 02 September 2023 - 02 September 2023.csv\n",
      "Product Reports 26 February 2024 - 26 February 2024.csv\n",
      "Product Reports 08 March 2024 - 08 March 2024.csv\n",
      "Product Reports 17 February 2023 - 17 February 2023.csv\n",
      "Product Reports 17 April 2023 - 17 April 2023.csv\n",
      "Product Reports 30 September 2023 - 30 September 2023.csv\n",
      "Product Reports 02 November 2023 - 02 November 2023.csv\n",
      "Product Reports 16 June 2022 - 16 June 2022.csv\n",
      "Product Reports 02 February 2023 - 02 February 2023.csv\n",
      "Product Reports 29 March 2022 - 29 March 2022.csv\n",
      "Product Reports 08 March 2023 - 08 March 2023.csv\n",
      "Product Reports 17 November 2023 - 17 November 2023.csv\n",
      "Product Reports 03 September 2023 - 03 September 2023.csv\n",
      "Product Reports 21 July 2022 - 21 July 2022.csv\n",
      "Product Reports 09 April 2023 - 09 April 2023.csv\n",
      "Product Reports 28 February 2024 - 28 February 2024.csv\n",
      "Product Reports 28 April 2022 - 28 April 2022.csv\n",
      "Product Reports 17 October 2022 - 17 October 2022.csv\n",
      "Product Reports 11 October 2023 - 11 October 2023.csv\n",
      "Product Reports 20 July 2022 - 20 July 2022.csv\n",
      "Product Reports 19 February 2023 - 19 February 2023.csv\n",
      "Product Reports 16 March 2024 - 16 March 2024.csv\n",
      "Product Reports 22 July 2022 - 22 July 2022.csv\n",
      "Product Reports 09 July 2022 - 09 July 2022.csv\n",
      "Product Reports 25 January 2022 - 25 January 2022.csv\n",
      "Product Reports 08 March 2022 - 08 March 2022.csv\n",
      "Product Reports 23 January 2023 - 23 January 2023.csv\n",
      "Product Reports 17 January 2024 - 17 January 2024.csv\n",
      "Product Reports 29 March 2023 - 29 March 2023.csv\n",
      "Product Reports 21 February 2022 - 21 February 2022.csv\n",
      "Product Reports 25 August 2023 - 25 August 2023.csv\n",
      "Product Reports 28 April 2023 - 28 April 2023.csv\n",
      "Product Reports 23 December 2022 - 23 December 2022.csv\n",
      "Product Reports 20 August 2022 - 20 August 2022.csv\n",
      "Product Reports 09 April 2022 - 09 April 2022.csv\n",
      "Product Reports 19 October 2023 - 19 October 2023.csv\n",
      "Product Reports 08 July 2022 - 08 July 2022.csv\n",
      "Product Reports 23 July 2022 - 23 July 2022.csv\n",
      "Product Reports 01 December 2023 - 01 December 2023.csv\n",
      "Product Reports 29 February 2024 - 29 February 2024.csv\n",
      "Product Reports 14 May 2022 - 14 May 2022.csv\n",
      "Product Reports 18 February 2023 - 18 February 2023.csv\n",
      "Product Reports 23 June 2022 - 23 June 2022.csv\n",
      "Product Reports 08 June 2022 - 08 June 2022.csv\n",
      "Product Reports 16 January 2024 - 16 January 2024.csv\n",
      "Product Reports 22 January 2023 - 22 January 2023.csv\n",
      "Product Reports 24 January 2022 - 24 January 2022.csv\n",
      "Product Reports 20 September 2023 - 20 September 2023.csv\n",
      "Product Reports 09 June 2022 - 09 June 2022.csv\n",
      "Product Reports 22 June 2022 - 22 June 2022.csv\n",
      "Product Reports 16 November 2023 - 16 November 2023.csv\n",
      "Product Reports 03 March 2024 - 03 March 2024.csv\n",
      "Product Reports 03 February 2023 - 03 February 2023.csv\n",
      "Product Reports 12 September 2023 - 12 September 2023.csv\n",
      "Product Reports 18 October 2023 - 18 October 2023.csv\n",
      "Product Reports 20 June 2022 - 20 June 2022.csv\n",
      "Product Reports 22 December 2022 - 22 December 2022.csv\n",
      "Product Reports 10 October 2023 - 10 October 2023.csv\n",
      "Product Reports 16 October 2022 - 16 October 2022.csv\n",
      "Product Reports 30 August 2022 - 30 August 2022.csv\n",
      "Product Reports 21 June 2022 - 21 June 2022.csv\n",
      "Product Reports 20 February 2022 - 20 February 2022.csv\n",
      "Product Reports 04 April 2022 - 04 April 2022.csv\n",
      "Product Reports 25 April 2023 - 25 April 2023.csv\n",
      "Product Reports 01 January 2024 - 01 January 2024.csv\n",
      "Product Reports 08 December 2022 - 08 December 2022.csv\n",
      "Product Reports 04 November 2022 - 04 November 2022.csv\n",
      "Product Reports 11 February 2022 - 11 February 2022.csv\n",
      "Product Reports 09 October 2022 - 09 October 2022.csv\n",
      "Product Reports 13 December 2022 - 13 December 2022.csv\n",
      "Product Reports 24 March 2023 - 24 March 2023.csv\n",
      "Product Reports 05 March 2022 - 05 March 2022.csv\n",
      "Product Reports 25 April 2022 - 25 April 2022.csv\n",
      "Product Reports 03 February 2024 - 03 February 2024.csv\n",
      "Product Reports 04 April 2023 - 04 April 2023.csv\n",
      "Product Reports 10 September 2023 - 10 September 2023.csv\n",
      "Product Reports 22 September 2023 - 22 September 2023.csv\n",
      "Product Reports 09 January 2024 - 09 January 2024.csv\n",
      "Product Reports 27 November 2023 - 27 November 2023.csv\n",
      "Product Reports 03 August 2023 - 03 August 2023.csv\n",
      "Product Reports 18 February 2024 - 18 February 2024.csv\n",
      "Product Reports 06 August 2022 - 06 August 2022.csv\n",
      "Product Reports 30 December 2023 - 30 December 2023.csv\n",
      "Product Reports 09 August 2023 - 09 August 2023.csv\n",
      "Product Reports 05 March 2023 - 05 March 2023.csv\n",
      "Product Reports 11 May 2023 - 11 May 2023.csv\n",
      "Product Reports 13 May 2022 - 13 May 2022.csv\n",
      "Product Reports 01 October 2022 - 01 October 2022.csv\n",
      "Product Reports 24 March 2022 - 24 March 2022.csv\n",
      "Product Reports 07 October 2023 - 07 October 2023.csv\n",
      "Product Reports 30 April 2023 - 30 April 2023.csv\n",
      "Product Reports 12 December 2022 - 12 December 2022.csv\n",
      "Product Reports 11 April 2022 - 11 April 2022.csv\n",
      "Product Reports 08 January 2024 - 08 January 2024.csv\n",
      "Product Reports 09 December 2022 - 09 December 2022.csv\n",
      "Product Reports 06 October 2023 - 06 October 2023.csv\n",
      "Product Reports 10 March 2022 - 10 March 2022.csv\n",
      "Product Reports 10 February 2022 - 10 February 2022.csv\n",
      "Product Reports 31 March 2023 - 31 March 2023.csv\n",
      "Product Reports 05 November 2022 - 05 November 2022.csv\n",
      "Product Reports 31 December 2023 - 31 December 2023.csv\n",
      "Product Reports 11 April 2023 - 11 April 2023.csv\n",
      "Product Reports 19 February 2024 - 19 February 2024.csv\n",
      "Product Reports 30 April 2022 - 30 April 2022.csv\n",
      "Product Reports 28 February 2023 - 28 February 2023.csv\n",
      "Product Reports 02 February 2024 - 02 February 2024.csv\n",
      "Product Reports 19 August 2023 - 19 August 2023.csv\n",
      "Product Reports 13 August 2023 - 13 August 2023.csv\n",
      "Product Reports 08 October 2022 - 08 October 2022.csv\n",
      "Product Reports 01 September 2023 - 01 September 2023.csv\n",
      "Product Reports 16 August 2022 - 16 August 2022.csv\n",
      "Product Reports 26 November 2023 - 26 November 2023.csv\n",
      "Product Reports 31 March 2022 - 31 March 2022.csv\n",
      "Product Reports 10 March 2023 - 10 March 2023.csv\n",
      "Product Reports 17 February 2024 - 17 February 2024.csv\n",
      "Product Reports 10 March 2024 - 10 March 2024.csv\n",
      "Product Reports 11 August 2023 - 11 August 2023.csv\n",
      "Product Reports 26 February 2023 - 26 February 2023.csv\n",
      "Product Reports 14 August 2022 - 14 August 2022.csv\n",
      "Product Reports 24 December 2023 - 24 December 2023.csv\n",
      "Product Reports 04 October 2023 - 04 October 2023.csv\n",
      "Product Reports 02 October 2022 - 02 October 2022.csv\n",
      "Product Reports 28 November 2023 - 28 November 2023.csv\n",
      "Product Reports 05 February 2022 - 05 February 2022.csv\n",
      "Product Reports 30 January 2022 - 30 January 2022.csv\n",
      "Product Reports 10 November 2022 - 10 November 2022.csv\n",
      "Product Reports 02 January 2024 - 02 January 2024.csv\n",
      "Product Reports 07 December 2022 - 07 December 2022.csv\n",
      "Product Reports 16 May 2022 - 16 May 2022.csv\n",
      "Product Reports 05 March 2024 - 05 March 2024.csv\n",
      "Product Reports 01 August 2023 - 01 August 2023.csv\n",
      "Product Reports 29 November 2023 - 29 November 2023.csv\n",
      "Product Reports 03 January 2024 - 03 January 2024.csv\n",
      "Product Reports 04 August 2022 - 04 August 2022.csv\n",
      "Product Reports 31 January 2022 - 31 January 2022.csv\n",
      "Product Reports 30 May 2022 - 30 May 2022.csv\n",
      "Product Reports 23 September 2023 - 23 September 2023.csv\n",
      "Product Reports 16 February 2024 - 16 February 2024.csv\n",
      "Product Reports 27 February 2023 - 27 February 2023.csv\n",
      "Product Reports 11 September 2023 - 11 September 2023.csv\n",
      "Product Reports 06 December 2022 - 06 December 2022.csv\n",
      "Product Reports 29 July 2023 - 29 July 2023.csv\n",
      "Product Reports 03 October 2022 - 03 October 2022.csv\n",
      "Product Reports 05 October 2023 - 05 October 2023.csv\n",
      "Product Reports 28 July 2023 - 28 July 2023.csv\n",
      "Product Reports 11 November 2022 - 11 November 2022.csv\n",
      "Product Reports 04 February 2022 - 04 February 2022.csv\n",
      "Product Reports 11 March 2024 - 11 March 2024.csv\n",
      "Product Reports 24 December 2022 - 24 December 2022.csv\n",
      "Product Reports 28 November 2022 - 28 November 2022.csv\n",
      "Product Reports 10 January 2023 - 10 January 2023.csv\n",
      "Product Reports 26 February 2022 - 26 February 2022.csv\n",
      "Product Reports 16 January 2022 - 16 January 2022.csv\n",
      "Product Reports 24 January 2024 - 24 January 2024.csv\n",
      "Product Reports 07 December 2023 - 07 December 2023.csv\n",
      "Product Reports 22 October 2023 - 22 October 2023.csv\n",
      "Product Reports 27 September 2023 - 27 September 2023.csv\n",
      "Product Reports 24 October 2022 - 24 October 2022.csv\n",
      "Product Reports 15 September 2023 - 15 September 2023.csv\n",
      "Product Reports 30 August 2023 - 30 August 2023.csv\n",
      "Product Reports 18 January 2023 - 18 January 2023.csv\n",
      "Product Reports 10 November 2023 - 10 November 2023.csv\n",
      "Product Reports 10 May 2022 - 10 May 2022.csv\n",
      "Product Reports 05 February 2023 - 05 February 2023.csv\n",
      "Product Reports 25 October 2022 - 25 October 2022.csv\n",
      "Product Reports 29 September 2022 - 29 September 2022.csv\n",
      "Product Reports 23 October 2023 - 23 October 2023.csv\n",
      "Product Reports 04 March 2024 - 04 March 2024.csv\n",
      "Product Reports 24 July 2023 - 24 July 2023.csv\n",
      "Product Reports 18 May 2022 - 18 May 2022.csv\n",
      "Product Reports 27 February 2022 - 27 February 2022.csv\n",
      "Product Reports 25 July 2023 - 25 July 2023.csv\n",
      "Product Reports 19 January 2023 - 19 January 2023.csv\n",
      "Product Reports 29 November 2022 - 29 November 2022.csv\n",
      "Product Reports 27 July 2023 - 27 July 2023.csv\n",
      "Product Reports 04 February 2023 - 04 February 2023.csv\n",
      "Product Reports 11 November 2023 - 11 November 2023.csv\n",
      "Product Reports 06 December 2023 - 06 December 2023.csv\n",
      "Product Reports 20 August 2023 - 20 August 2023.csv\n",
      "Product Reports 25 August 2022 - 25 August 2022.csv\n",
      "Product Reports 25 January 2024 - 25 January 2024.csv\n",
      "Product Reports 26 July 2023 - 26 July 2023.csv\n",
      "Product Reports 04 September 2023 - 04 September 2023.csv\n",
      "Product Reports 17 January 2022 - 17 January 2022.csv\n",
      "Product Reports 11 January 2023 - 11 January 2023.csv\n",
      "Product Reports 24 April 2023 - 24 April 2023.csv\n",
      "Product Reports 13 December 2023 - 13 December 2023.csv\n",
      "Product Reports 05 April 2022 - 05 April 2022.csv\n",
      "Product Reports 05 September 2023 - 05 September 2023.csv\n",
      "Product Reports 28 August 2023 - 28 August 2023.csv\n",
      "Product Reports 22 August 2023 - 22 August 2023.csv\n",
      "Product Reports 27 October 2022 - 27 October 2022.csv\n",
      "Product Reports 27 August 2022 - 27 August 2022.csv\n",
      "Product Reports 21 October 2023 - 21 October 2023.csv\n",
      "Product Reports 08 December 2023 - 08 December 2023.csv\n",
      "Product Reports 20 February 2024 - 20 February 2024.csv\n",
      "Product Reports 04 March 2022 - 04 March 2022.csv\n",
      "Product Reports 11 February 2023 - 11 February 2023.csv\n",
      "Product Reports 25 March 2023 - 25 March 2023.csv\n",
      "Product Reports 04 November 2023 - 04 November 2023.csv\n",
      "Product Reports 29 October 2023 - 29 October 2023.csv\n",
      "Product Reports 05 April 2023 - 05 April 2023.csv\n",
      "Product Reports 30 December 2022 - 30 December 2022.csv\n",
      "Product Reports 24 April 2022 - 24 April 2022.csv\n",
      "Product Reports 15 January 2022 - 15 January 2022.csv\n",
      "Product Reports 13 January 2023 - 13 January 2023.csv\n",
      "Product Reports 27 January 2024 - 27 January 2024.csv\n",
      "Product Reports 25 March 2022 - 25 March 2022.csv\n",
      "Product Reports 27 November 2022 - 27 November 2022.csv\n",
      "Product Reports 28 September 2022 - 28 September 2022.csv\n",
      "Product Reports 04 March 2023 - 04 March 2023.csv\n",
      "Product Reports 15 May 2022 - 15 May 2022.csv\n",
      "Product Reports 21 February 2024 - 21 February 2024.csv\n",
      "Product Reports 10 April 2022 - 10 April 2022.csv\n",
      "Product Reports 09 December 2023 - 09 December 2023.csv\n",
      "Product Reports 28 October 2023 - 28 October 2023.csv\n",
      "Product Reports 05 November 2023 - 05 November 2023.csv\n",
      "Product Reports 13 July 2023 - 13 July 2023.csv\n",
      "Product Reports 10 February 2023 - 10 February 2023.csv\n",
      "Product Reports 12 December 2023 - 12 December 2023.csv\n",
      "Product Reports 26 January 2024 - 26 January 2024.csv\n",
      "Product Reports 12 January 2023 - 12 January 2023.csv\n",
      "Product Reports 12 July 2023 - 12 July 2023.csv\n",
      "Product Reports 14 January 2022 - 14 January 2022.csv\n",
      "Product Reports 14 September 2023 - 14 September 2023.csv\n",
      "Product Reports 26 September 2023 - 26 September 2023.csv\n",
      "Product Reports 30 March 2023 - 30 March 2023.csv\n",
      "Product Reports 11 March 2022 - 11 March 2022.csv\n",
      "Product Reports 10 July 2023 - 10 July 2023.csv\n",
      "Product Reports 10 April 2023 - 10 April 2023.csv\n",
      "Product Reports 20 October 2023 - 20 October 2023.csv\n",
      "Product Reports 26 October 2022 - 26 October 2022.csv\n",
      "Product Reports 26 November 2022 - 26 November 2022.csv\n",
      "Product Reports 31 December 2022 - 31 December 2022.csv\n",
      "Product Reports 11 March 2023 - 11 March 2023.csv\n",
      "Product Reports 11 July 2023 - 11 July 2023.csv\n",
      "Product Reports 28 February 2022 - 28 February 2022.csv\n",
      "Product Reports 30 March 2022 - 30 March 2022.csv\n",
      "Product Reports 04 July 2022 - 04 July 2022.csv\n",
      "Product Reports 09 March 2023 - 09 March 2023.csv\n",
      "Product Reports 19 February 2022 - 19 February 2022.csv\n",
      "Product Reports 04 August 2023 - 04 August 2023.csv\n",
      "Product Reports 28 March 2022 - 28 March 2022.csv\n",
      "Product Reports 01 August 2022 - 01 August 2022.csv\n",
      "Product Reports 29 April 2022 - 29 April 2022.csv\n",
      "Product Reports 08 April 2023 - 08 April 2023.csv\n",
      "Product Reports 03 January 2022 - 03 January 2022.csv\n",
      "Product Reports 09 September 2022 - 09 September 2022.csv\n",
      "Product Reports 17 March 2024 - 17 March 2024.csv\n",
      "Product Reports 05 January 2023 - 05 January 2023.csv\n",
      "Product Reports 17 November 2022 - 17 November 2022.csv\n",
      "Product Reports 31 January 2024 - 31 January 2024.csv\n",
      "Product Reports 05 July 2022 - 05 July 2022.csv\n",
      "Product Reports 02 February 2022 - 02 February 2022.csv\n",
      "Product Reports 24 September 2023 - 24 September 2023.csv\n",
      "Product Reports 31 October 2022 - 31 October 2022.csv\n",
      "Product Reports 23 December 2023 - 23 December 2023.csv\n",
      "Product Reports 28 March 2023 - 28 March 2023.csv\n",
      "Product Reports 07 July 2022 - 07 July 2022.csv\n",
      "Product Reports 09 March 2022 - 09 March 2022.csv\n",
      "Product Reports 16 September 2023 - 16 September 2023.csv\n",
      "Product Reports 08 April 2022 - 08 April 2022.csv\n",
      "Product Reports 06 July 2022 - 06 July 2022.csv\n",
      "Product Reports 29 April 2023 - 29 April 2023.csv\n",
      "Product Reports 10 February 2024 - 10 February 2024.csv\n",
      "Product Reports 21 February 2023 - 21 February 2023.csv\n",
      "Product Reports 06 June 2022 - 06 June 2022.csv\n",
      "Product Reports 30 October 2022 - 30 October 2022.csv\n",
      "Product Reports 10 May 2023 - 10 May 2023.csv\n",
      "Product Reports 12 May 2022 - 12 May 2022.csv\n",
      "Product Reports 14 August 2023 - 14 August 2023.csv\n",
      "Product Reports 03 February 2022 - 03 February 2022.csv\n",
      "Product Reports 18 September 2022 - 18 September 2022.csv\n",
      "Product Reports 11 August 2022 - 11 August 2022.csv\n",
      "Product Reports 16 November 2022 - 16 November 2022.csv\n",
      "Product Reports 01 December 2022 - 01 December 2022.csv\n",
      "Product Reports 07 June 2022 - 07 June 2022.csv\n",
      "Product Reports 02 March 2024 - 02 March 2024.csv\n",
      "Product Reports 18 February 2022 - 18 February 2022.csv\n",
      "Product Reports 11 February 2024 - 11 February 2024.csv\n",
      "Product Reports 05 June 2022 - 05 June 2022.csv\n",
      "Product Reports 20 February 2023 - 20 February 2023.csv\n",
      "Product Reports 22 December 2023 - 22 December 2023.csv\n",
      "Product Reports 04 June 2022 - 04 June 2022.csv\n",
      "Product Reports 30 January 2024 - 30 January 2024.csv\n",
      "Product Reports 04 January 2023 - 04 January 2023.csv\n",
      "Product Reports 07 September 2023 - 07 September 2023.csv\n",
      "Product Reports 02 January 2022 - 02 January 2022.csv\n",
      "Product Reports 02 March 2022 - 02 March 2022.csv\n",
      "Product Reports 18 July 2022 - 18 July 2022.csv\n",
      "Product Reports 06 September 2023 - 06 September 2023.csv\n",
      "Product Reports 23 March 2023 - 23 March 2023.csv\n",
      "Product Reports 04 February 2024 - 04 February 2024.csv\n",
      "Product Reports 20 November 2023 - 20 November 2023.csv\n",
      "Product Reports 22 April 2023 - 22 April 2023.csv\n",
      "Product Reports 19 July 2022 - 19 July 2022.csv\n",
      "Product Reports 03 April 2022 - 03 April 2022.csv\n",
      "Product Reports 08 January 2022 - 08 January 2022.csv\n",
      "Product Reports 23 March 2022 - 23 March 2022.csv\n",
      "Product Reports 02 March 2023 - 02 March 2023.csv\n",
      "Product Reports 14 December 2022 - 14 December 2022.csv\n",
      "Product Reports 30 July 2022 - 30 July 2022.csv\n",
      "Product Reports 18 November 2022 - 18 November 2022.csv\n",
      "Product Reports 16 August 2023 - 16 August 2023.csv\n",
      "Product Reports 31 July 2022 - 31 July 2022.csv\n",
      "Product Reports 06 January 2023 - 06 January 2023.csv\n",
      "Product Reports 13 August 2022 - 13 August 2022.csv\n",
      "Product Reports 19 August 2022 - 19 August 2022.csv\n",
      "Product Reports 19 September 2022 - 19 September 2022.csv\n",
      "Product Reports 31 May 2022 - 31 May 2022.csv\n",
      "Product Reports 03 April 2023 - 03 April 2023.csv\n",
      "Product Reports 16 February 2022 - 16 February 2022.csv\n",
      "Product Reports 22 April 2022 - 22 April 2022.csv\n",
      "Product Reports 03 November 2022 - 03 November 2022.csv\n",
      "Product Reports 17 May 2022 - 17 May 2022.csv\n",
      "Product Reports 05 February 2024 - 05 February 2024.csv\n",
      "Product Reports 17 March 2022 - 17 March 2022.csv\n",
      "Product Reports 21 November 2023 - 21 November 2023.csv\n",
      "Product Reports 17 September 2023 - 17 September 2023.csv\n",
      "Product Reports 01 January 2022 - 01 January 2022.csv\n",
      "Product Reports 07 January 2023 - 07 January 2023.csv\n",
      "Product Reports 16 April 2022 - 16 April 2022.csv\n",
      "Product Reports 30 June 2022 - 30 June 2022.csv\n",
      "Product Reports 25 September 2023 - 25 September 2023.csv\n",
      "Product Reports 17 March 2023 - 17 March 2023.csv\n",
      "Product Reports 08 September 2022 - 08 September 2022.csv\n",
      "Product Reports 02 November 2022 - 02 November 2022.csv\n",
      "Product Reports 19 June 2022 - 19 June 2022.csv\n",
      "Product Reports 17 February 2022 - 17 February 2022.csv\n",
      "Product Reports 09 March 2024 - 09 March 2024.csv\n",
      "Product Reports 09 August 2022 - 09 August 2022.csv\n",
      "Product Reports 15 December 2022 - 15 December 2022.csv\n",
      "Product Reports 06 August 2023 - 06 August 2023.csv\n",
      "Product Reports 18 June 2022 - 18 June 2022.csv\n",
      "Product Reports 03 August 2022 - 03 August 2022.csv\n",
      "Product Reports 09 January 2022 - 09 January 2022.csv\n",
      "Product Reports 16 April 2023 - 16 April 2023.csv\n",
      "Product Reports 19 November 2022 - 19 November 2022.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "data_root = \"data/daily\"\n",
    "files = os.listdir(data_root)\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    match = re.search(r'\\d{2} (.*?) \\d{4}', file)\n",
    "    if match is None: print(file)\n",
    "    # year = re.search(r'\\d{4}', file).group()\n",
    "    date = datetime.strptime(match.group(), r\"%d %B %Y\").date()\n",
    "    # print(match.group())\n",
    "    df = pd.read_csv(f\"{data_root}/{file}\")\n",
    "    df[\"date\"] = date\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Menu Item Name</th>\n",
       "      <th>Menu Category</th>\n",
       "      <th>QTY sold</th>\n",
       "      <th>Sales exc Tax.</th>\n",
       "      <th>Discounts</th>\n",
       "      <th>Sales inc Tax.(a)</th>\n",
       "      <th>Cost inc Tax(b)</th>\n",
       "      <th>Gross Profit(a)-(b)</th>\n",
       "      <th>Markup Percentage %(a-b)/b * 100%</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.Dwaeji galbi ribs(default)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>1</td>\n",
       "      <td>£ 12.29</td>\n",
       "      <td>£ 0.00</td>\n",
       "      <td>£ 12.90</td>\n",
       "      <td>£ 0.00</td>\n",
       "      <td>£ 12.90</td>\n",
       "      <td>0 %</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.beef Bulgogi(Standard)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>1</td>\n",
       "      <td>£ 12.29</td>\n",
       "      <td>£ 0.00</td>\n",
       "      <td>£ 12.90</td>\n",
       "      <td>£ 0.00</td>\n",
       "      <td>£ 12.90</td>\n",
       "      <td>0 %</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.Chargrilled Squid(Standard)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>1</td>\n",
       "      <td>£ 12.29</td>\n",
       "      <td>£ 0.00</td>\n",
       "      <td>£ 12.90</td>\n",
       "      <td>£ 0.00</td>\n",
       "      <td>£ 12.90</td>\n",
       "      <td>0 %</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.Lettuce, Garlic &amp; Chilli(Standard)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>2</td>\n",
       "      <td>£ 6.67</td>\n",
       "      <td>£ 0.00</td>\n",
       "      <td>£ 7.00</td>\n",
       "      <td>£ 0.00</td>\n",
       "      <td>£ 7.00</td>\n",
       "      <td>0 %</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kirin Ichi Ban(Standard)</td>\n",
       "      <td>Bottled Beer &amp; Cider</td>\n",
       "      <td>1</td>\n",
       "      <td>£ 4.29</td>\n",
       "      <td>£ 0.00</td>\n",
       "      <td>£ 4.50</td>\n",
       "      <td>£ 0.00</td>\n",
       "      <td>£ 4.50</td>\n",
       "      <td>0 %</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Menu Item Name               Menu Category  \\\n",
       "0          53.Dwaeji galbi ribs(default)  RESTAURANT Grill BBQ 52-60   \n",
       "1              54.beef Bulgogi(Standard)  RESTAURANT Grill BBQ 52-60   \n",
       "2         57.Chargrilled Squid(Standard)  RESTAURANT Grill BBQ 52-60   \n",
       "3  58.Lettuce, Garlic & Chilli(Standard)  RESTAURANT Grill BBQ 52-60   \n",
       "4               Kirin Ichi Ban(Standard)        Bottled Beer & Cider   \n",
       "\n",
       "   QTY sold Sales exc Tax. Discounts Sales inc Tax.(a) Cost inc Tax(b)  \\\n",
       "0         1        £ 12.29    £ 0.00           £ 12.90          £ 0.00   \n",
       "1         1        £ 12.29    £ 0.00           £ 12.90          £ 0.00   \n",
       "2         1        £ 12.29    £ 0.00           £ 12.90          £ 0.00   \n",
       "3         2         £ 6.67    £ 0.00            £ 7.00          £ 0.00   \n",
       "4         1         £ 4.29    £ 0.00            £ 4.50          £ 0.00   \n",
       "\n",
       "  Gross Profit(a)-(b) Markup Percentage %(a-b)/b * 100%        date  \n",
       "0             £ 12.90                               0 %  2024-02-01  \n",
       "1             £ 12.90                               0 %  2024-02-01  \n",
       "2             £ 12.90                               0 %  2024-02-01  \n",
       "3              £ 7.00                               0 %  2024-02-01  \n",
       "4              £ 4.50                               0 %  2024-02-01  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87809, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing daily records. There are 2 possible reasons why a record is missing:\n",
    "1. The restaurant was closed that day e.g. holiday\n",
    "2. The file for the record is simply missing (can be obtained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2022-12-25', '2023-05-12', '2023-05-13', '2023-05-14',\n",
       "               '2023-05-15', '2023-05-16', '2023-05-17', '2023-05-18',\n",
       "               '2023-05-19', '2023-05-20', '2023-05-21', '2023-05-22',\n",
       "               '2023-05-23', '2023-05-24', '2023-05-25', '2023-05-26',\n",
       "               '2023-05-27', '2023-05-28', '2023-05-29', '2023-05-30',\n",
       "               '2023-05-31', '2023-06-01', '2023-06-02', '2023-06-03',\n",
       "               '2023-06-04', '2023-06-05', '2023-06-06', '2023-06-07',\n",
       "               '2023-06-08', '2023-06-09', '2023-06-10', '2023-06-11',\n",
       "               '2023-06-12', '2023-06-13', '2023-06-14', '2023-06-15',\n",
       "               '2023-06-16', '2023-06-17', '2023-06-18', '2023-06-19',\n",
       "               '2023-06-20', '2023-06-21', '2023-06-22', '2023-06-23',\n",
       "               '2023-06-24', '2023-06-25', '2023-06-26', '2023-06-27',\n",
       "               '2023-06-28', '2023-06-29', '2023-06-30', '2023-07-01',\n",
       "               '2023-07-02', '2023-07-03', '2023-07-04', '2023-07-05',\n",
       "               '2023-07-22', '2023-12-25'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range(start = '2022-01-01', end = '2024-02-29' ).difference(df.date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize missing records\n",
    "\n",
    "# missing_dates = pd.date_range(start = '2022-01-01', end = '2024-02-29' ).difference(df.date.unique()).to_frame()\n",
    "# missing_dates.columns = [\"date\"]\n",
    "# missing_dates = missing_dates.reset_index(drop=True)\n",
    "# missing_dates[\"is_missing\"] = True\n",
    "\n",
    "# missing_df = pd.DataFrame({\"date\": df.date.unique()})\n",
    "# missing_df[\"is_missing\"] = False\n",
    "\n",
    "# missing_df = pd.concat([missing_dates, missing_df])\n",
    "# missing_df.date = pd.to_datetime(missing_df.date)\n",
    "# missing_df = missing_df.set_index(\"date\")\n",
    "# missing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[8], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming columns for ease of manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Menu Item Name', 'Menu Category', 'QTY sold', 'Sales exc Tax.',\n",
       "       'Discounts', 'Sales inc Tax.(a)', 'Cost inc Tax(b)',\n",
       "       'Gross Profit(a)-(b)', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"name\", \"category\", \"sold\", \"sales_inc_tax\", \"discount\", \"sales_exc_tax\", \"cost_inc_tax\", \"gross_profit\", \"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87809 entries, 0 to 179\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   name           87809 non-null  object\n",
      " 1   category       86474 non-null  object\n",
      " 2   sold           87809 non-null  int64 \n",
      " 3   sales_inc_tax  87809 non-null  object\n",
      " 4   discount       87809 non-null  object\n",
      " 5   sales_exc_tax  87809 non-null  object\n",
      " 6   cost_inc_tax   87809 non-null  object\n",
      " 7   gross_profit   87809 non-null  object\n",
      " 8   date           87809 non-null  object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns that are supposed to be `float` are being parsed as `object`. This is due to the values having:\n",
    "- the currency sign (which in this case is `£`)\n",
    "- the percentage sign `%`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>sold</th>\n",
       "      <th>sales_inc_tax</th>\n",
       "      <th>discount</th>\n",
       "      <th>sales_exc_tax</th>\n",
       "      <th>cost_inc_tax</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.Dwaeji galbi ribs(default)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>1</td>\n",
       "      <td>12.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.beef Bulgogi(Standard)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>1</td>\n",
       "      <td>12.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.Chargrilled Squid(Standard)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>1</td>\n",
       "      <td>12.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.Lettuce, Garlic &amp; Chilli(Standard)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kirin Ichi Ban(Standard)</td>\n",
       "      <td>Bottled Beer &amp; Cider</td>\n",
       "      <td>1</td>\n",
       "      <td>4.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name                    category  sold  \\\n",
       "0          53.Dwaeji galbi ribs(default)  RESTAURANT Grill BBQ 52-60     1   \n",
       "1              54.beef Bulgogi(Standard)  RESTAURANT Grill BBQ 52-60     1   \n",
       "2         57.Chargrilled Squid(Standard)  RESTAURANT Grill BBQ 52-60     1   \n",
       "3  58.Lettuce, Garlic & Chilli(Standard)  RESTAURANT Grill BBQ 52-60     2   \n",
       "4               Kirin Ichi Ban(Standard)        Bottled Beer & Cider     1   \n",
       "\n",
       "   sales_inc_tax  discount  sales_exc_tax  cost_inc_tax  gross_profit  \\\n",
       "0          12.29       0.0           12.9           0.0          12.9   \n",
       "1          12.29       0.0           12.9           0.0          12.9   \n",
       "2          12.29       0.0           12.9           0.0          12.9   \n",
       "3           6.67       0.0            7.0           0.0           7.0   \n",
       "4           4.29       0.0            4.5           0.0           4.5   \n",
       "\n",
       "         date  \n",
       "0  2024-02-01  \n",
       "1  2024-02-01  \n",
       "2  2024-02-01  \n",
       "3  2024-02-01  \n",
       "4  2024-02-01  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currency_columns = [\"sales_inc_tax\", \"discount\", \"sales_exc_tax\", \"cost_inc_tax\", \"gross_profit\"]\n",
    "\n",
    "for col in currency_columns:\n",
    "    df[col] = df[col].str.replace(\"-|£|%\", \"\", regex=True).str.strip().astype(float)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87809 entries, 0 to 179\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   name           87809 non-null  object \n",
      " 1   category       86474 non-null  object \n",
      " 2   sold           87809 non-null  int64  \n",
      " 3   sales_inc_tax  87809 non-null  float64\n",
      " 4   discount       87809 non-null  float64\n",
      " 5   sales_exc_tax  87809 non-null  float64\n",
      " 6   cost_inc_tax   87809 non-null  float64\n",
      " 7   gross_profit   87809 non-null  float64\n",
      " 8   date           87809 non-null  object \n",
      "dtypes: float64(5), int64(1), object(3)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above the column types are fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sold</th>\n",
       "      <th>sales_inc_tax</th>\n",
       "      <th>discount</th>\n",
       "      <th>sales_exc_tax</th>\n",
       "      <th>cost_inc_tax</th>\n",
       "      <th>gross_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87809.000000</td>\n",
       "      <td>87809.000000</td>\n",
       "      <td>87809.000000</td>\n",
       "      <td>87809.000000</td>\n",
       "      <td>87809.0</td>\n",
       "      <td>87809.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.784453</td>\n",
       "      <td>32.637691</td>\n",
       "      <td>0.333108</td>\n",
       "      <td>34.144147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.144147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.103427</td>\n",
       "      <td>191.849225</td>\n",
       "      <td>2.645087</td>\n",
       "      <td>200.740288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.740288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.670000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>704.000000</td>\n",
       "      <td>4669.560000</td>\n",
       "      <td>120.090000</td>\n",
       "      <td>4884.380000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4884.380000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sold  sales_inc_tax      discount  sales_exc_tax  cost_inc_tax  \\\n",
       "count  87809.000000   87809.000000  87809.000000   87809.000000       87809.0   \n",
       "mean       4.784453      32.637691      0.333108      34.144147           0.0   \n",
       "std       28.103427     191.849225      2.645087     200.740288           0.0   \n",
       "min        1.000000       0.000000      0.000000       0.000000           0.0   \n",
       "25%        1.000000       6.670000      0.000000       7.000000           0.0   \n",
       "50%        2.000000      10.380000      0.000000      10.900000           0.0   \n",
       "75%        3.000000      20.760000      0.000000      21.800000           0.0   \n",
       "max      704.000000    4669.560000    120.090000    4884.380000           0.0   \n",
       "\n",
       "       gross_profit  \n",
       "count  87809.000000  \n",
       "mean      34.144147  \n",
       "std      200.740288  \n",
       "min        0.000000  \n",
       "25%        7.000000  \n",
       "50%       10.900000  \n",
       "75%       21.800000  \n",
       "max     4884.380000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empty and duplicate data\n",
    "Checking for empty values and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                0\n",
       "category         1335\n",
       "sold                0\n",
       "sales_inc_tax       0\n",
       "discount            0\n",
       "sales_exc_tax       0\n",
       "cost_inc_tax        0\n",
       "gross_profit        0\n",
       "date                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>sold</th>\n",
       "      <th>sales_inc_tax</th>\n",
       "      <th>discount</th>\n",
       "      <th>sales_exc_tax</th>\n",
       "      <th>cost_inc_tax</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Total Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191</td>\n",
       "      <td>1482.66</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1550.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1550.75</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prawn tempura rice (-)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>228.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>228.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.25</td>\n",
       "      <td>2023-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Total Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>354</td>\n",
       "      <td>2576.90</td>\n",
       "      <td>6.54</td>\n",
       "      <td>2689.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2689.46</td>\n",
       "      <td>2023-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>box(-)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2023-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Total Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>1140.15</td>\n",
       "      <td>22.03</td>\n",
       "      <td>1191.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1191.72</td>\n",
       "      <td>2023-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Total Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169</td>\n",
       "      <td>1135.16</td>\n",
       "      <td>13.12</td>\n",
       "      <td>1187.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1187.98</td>\n",
       "      <td>2022-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>takeaway box(-)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2023-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Total Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>1552.80</td>\n",
       "      <td>12.63</td>\n",
       "      <td>1628.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1628.22</td>\n",
       "      <td>2023-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>container(-)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2022-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Total Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>703</td>\n",
       "      <td>4473.81</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4684.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4684.58</td>\n",
       "      <td>2022-11-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1335 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name category  sold  sales_inc_tax  discount  \\\n",
       "102             Total Sales      NaN   191        1482.66      2.40   \n",
       "0    prawn tempura rice (-)      NaN    11         228.25      0.00   \n",
       "135             Total Sales      NaN   354        2576.90      6.54   \n",
       "0                    box(-)      NaN     1           0.17      0.08   \n",
       "99              Total Sales      NaN   172        1140.15     22.03   \n",
       "..                      ...      ...   ...            ...       ...   \n",
       "91              Total Sales      NaN   169        1135.16     13.12   \n",
       "0           takeaway box(-)      NaN     8           2.00      0.00   \n",
       "110             Total Sales      NaN   240        1552.80     12.63   \n",
       "0              container(-)      NaN    15           3.75      0.00   \n",
       "179             Total Sales      NaN   703        4473.81      3.87   \n",
       "\n",
       "     sales_exc_tax  cost_inc_tax  gross_profit        date  \n",
       "102        1550.75           0.0       1550.75  2024-02-01  \n",
       "0           228.25           0.0        228.25  2023-12-29  \n",
       "135        2689.46           0.0       2689.46  2023-12-29  \n",
       "0             0.17           0.0          0.17  2023-07-06  \n",
       "99         1191.72           0.0       1191.72  2023-07-06  \n",
       "..             ...           ...           ...         ...  \n",
       "91         1187.98           0.0       1187.98  2022-01-09  \n",
       "0             2.00           0.0          2.00  2023-04-16  \n",
       "110        1628.22           0.0       1628.22  2023-04-16  \n",
       "0             3.75           0.0          3.75  2022-11-19  \n",
       "179        4684.58           0.0       4684.58  2022-11-19  \n",
       "\n",
       "[1335 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.category.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, there are some legitimate products with no category. The other ones are `Total Sales` just noise.\n",
    "\n",
    "I will remove these as they are not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.name == \"Total Sales\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name               0\n",
       "category         586\n",
       "sold               0\n",
       "sales_inc_tax      0\n",
       "discount           0\n",
       "sales_exc_tax      0\n",
       "cost_inc_tax       0\n",
       "gross_profit       0\n",
       "date               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining products with no category are custom sales that are not at the menu at the time.\n",
    "Thus I will replace it with `custom` category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>sold</th>\n",
       "      <th>sales_inc_tax</th>\n",
       "      <th>discount</th>\n",
       "      <th>sales_exc_tax</th>\n",
       "      <th>cost_inc_tax</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.Dwaeji galbi ribs(default)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>1</td>\n",
       "      <td>12.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.beef Bulgogi(Standard)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>1</td>\n",
       "      <td>12.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.Chargrilled Squid(Standard)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>1</td>\n",
       "      <td>12.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.Lettuce, Garlic &amp; Chilli(Standard)</td>\n",
       "      <td>RESTAURANT Grill BBQ 52-60</td>\n",
       "      <td>2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kirin Ichi Ban(Standard)</td>\n",
       "      <td>Bottled Beer &amp; Cider</td>\n",
       "      <td>1</td>\n",
       "      <td>4.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name                    category  sold  \\\n",
       "0          53.Dwaeji galbi ribs(default)  RESTAURANT Grill BBQ 52-60     1   \n",
       "1              54.beef Bulgogi(Standard)  RESTAURANT Grill BBQ 52-60     1   \n",
       "2         57.Chargrilled Squid(Standard)  RESTAURANT Grill BBQ 52-60     1   \n",
       "3  58.Lettuce, Garlic & Chilli(Standard)  RESTAURANT Grill BBQ 52-60     2   \n",
       "4               Kirin Ichi Ban(Standard)        Bottled Beer & Cider     1   \n",
       "\n",
       "   sales_inc_tax  discount  sales_exc_tax  cost_inc_tax  gross_profit  \\\n",
       "0          12.29       0.0           12.9           0.0          12.9   \n",
       "1          12.29       0.0           12.9           0.0          12.9   \n",
       "2          12.29       0.0           12.9           0.0          12.9   \n",
       "3           6.67       0.0            7.0           0.0           7.0   \n",
       "4           4.29       0.0            4.5           0.0           4.5   \n",
       "\n",
       "         date  \n",
       "0  2024-02-01  \n",
       "1  2024-02-01  \n",
       "2  2024-02-01  \n",
       "3  2024-02-01  \n",
       "4  2024-02-01  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = df.fillna(\"custom\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by quantity sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>sold</th>\n",
       "      <th>sales_inc_tax</th>\n",
       "      <th>discount</th>\n",
       "      <th>sales_exc_tax</th>\n",
       "      <th>cost_inc_tax</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asahi(Pint)</td>\n",
       "      <td>Draught Beer</td>\n",
       "      <td>82</td>\n",
       "      <td>406.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>426.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426.40</td>\n",
       "      <td>2022-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asahi(Pint)</td>\n",
       "      <td>Draught Beer</td>\n",
       "      <td>64</td>\n",
       "      <td>316.46</td>\n",
       "      <td>0.52</td>\n",
       "      <td>332.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332.28</td>\n",
       "      <td>2022-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asahi(Pint)</td>\n",
       "      <td>Draught Beer</td>\n",
       "      <td>63</td>\n",
       "      <td>312.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>327.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327.60</td>\n",
       "      <td>2023-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asahi(Pint)</td>\n",
       "      <td>Draught Beer</td>\n",
       "      <td>63</td>\n",
       "      <td>312.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>327.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327.60</td>\n",
       "      <td>2023-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asahi(Pint)</td>\n",
       "      <td>Draught Beer</td>\n",
       "      <td>62</td>\n",
       "      <td>306.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>321.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>321.88</td>\n",
       "      <td>2022-05-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name      category  sold  sales_inc_tax  discount  sales_exc_tax  \\\n",
       "0  Asahi(Pint)  Draught Beer    82         406.10      0.00         426.40   \n",
       "1  Asahi(Pint)  Draught Beer    64         316.46      0.52         332.28   \n",
       "2  Asahi(Pint)  Draught Beer    63         312.00      0.00         327.60   \n",
       "3  Asahi(Pint)  Draught Beer    63         312.00      0.00         327.60   \n",
       "4  Asahi(Pint)  Draught Beer    62         306.55      0.52         321.88   \n",
       "\n",
       "   cost_inc_tax  gross_profit        date  \n",
       "0           0.0        426.40  2022-11-12  \n",
       "1           0.0        332.28  2022-10-08  \n",
       "2           0.0        327.60  2023-01-10  \n",
       "3           0.0        327.60  2023-11-25  \n",
       "4           0.0        321.88  2022-05-21  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(\"sold\", ascending=False, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Standardisation\n",
    "\n",
    "- (easy) name and categories must be lowercase\n",
    "- (easy) add a new column to classify drinks and food `is_food`\n",
    "- (hard) some names are different but refer to same product: combine these\n",
    "- (medium) some categories are different but refer to same category: combine these\n",
    "- (easy) remove unnecessary noise from the names and categories e.g. product number, emojis\n",
    "- (medium) introduce a new column: `variant` for more granular analysis. To illustrate:\n",
    "\n",
    "| name |\n",
    "|------|\n",
    "|bibimbap(beef)|\n",
    "\n",
    "into\n",
    "\n",
    "| name | variant |\n",
    "|------|---------|\n",
    "| bibimbap | beef |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name = df.name.str.lower()\n",
    "df.category = df.category.str.lower()\n",
    "\n",
    "df.name = df.name.str.replace(\"^(\\d{1,2}\\.?)\\s*\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['draught beer', 'donburi 29-39', 'soft drinks', 'cocktails',\n",
       "       'korean starter 53-61', 'donburi 29-38', 'sides', 'custom',\n",
       "       'sides extras', 'japan rice dis 25-32', 'restaurant special',\n",
       "       'spirits', 'traditional 1-14', 'buns 24-28', 'traditional 1-15',\n",
       "       'lunch bento', 'noodles 47-48', 'buns 25-26',\n",
       "       'bottled beer & cider', 'buns 33-38', 'bbq (korean) 75 - 84',\n",
       "       'korean soft drinks', 'japanese side 1-13', 'korean soju',\n",
       "       'korean side 14-24', 'tea / coffee', 'special mains 39-46',\n",
       "       'sushi', 'set menu', 'sushi rolls (4pc)', 'vegan',\n",
       "       'ramen & noodle 39-40', 'spirits & shots', 'rice dishes 70-74',\n",
       "       'dessert', 'white wine', 'robata grill 15-23',\n",
       "       'korean dishes 41-51', 'asian cocktails', 'korean sides 49-52',\n",
       "       'robata grill 16-24', 'soup 66-69', 'korean nood 62-64',\n",
       "       'korean set menu', 'classic cocktails', 'korean nood 62-65',\n",
       "       'rose wine', 'red wine', 'other', 'restaurant grill bbq 52-60',\n",
       "       'sushi rolls 4pc/8pc', 'mocktails', 'champagne', 'platters 45-46',\n",
       "       'restaurant specials', 'sushi platters', 'platters 27-28',\n",
       "       'bbq platters 59-60', 'extras', 'new items', 'hotpot',\n",
       "       'seared salmon nigiri'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asahi(pint)', 'chicken katsu curry(standard)', 'tap water(glass)',\n",
       "       'peroni(pint)', 'cocktail(-)', 'coke(standard)', 'stella(pint)',\n",
       "       'diet coke(standard)', 'mandu (5pc)(standard)',\n",
       "       'chilli fries(standard)', 'pan seared seabass(-)',\n",
       "       'camden pale ale(pint)', 'ramen pork belly w/extra veg(-)',\n",
       "       'lemonade(standard)', 'drinks(-)', 'takeaway box(-)',\n",
       "       'egg fried rice(-)', 'mocktail(-)', 'restaurant special set',\n",
       "       'tequila(standard)', 'steamed rice(standard)',\n",
       "       'prawn tempura(standard)', 'asahi(half)', 'trial(-)', 'box(-)',\n",
       "       'asia daisy(standard)', 'crispy duck bun',\n",
       "       'bento mandu dumplings(4pc)(-)', 'yaki soba(chicken)',\n",
       "       'chicken teriyaki(standard)', 'lucky buddha(-)', 'container(-)',\n",
       "       'fever tree tonic(standard)', 'tequila(-)',\n",
       "       'kimchi fried rice chix and pork(-)', 'chicken harumaki(standard)',\n",
       "       'rib eye(standard)', 'chicken katsu  curry 日式咖喱鸡(-)',\n",
       "       'singha lager', 'aloe vera(standard)', 'chicken katsu bun',\n",
       "       'spicy squid(standard)', 'sweet potato fries(-)',\n",
       "       'restaurant special set with seafood pancake(-)',\n",
       "       'vegetable tempura(standard)', 'duck harumaki(standard)',\n",
       "       'restaurant special set(-)', 'yaki soba vegetable 1/2 portion(-)',\n",
       "       'corona(-)', 'bento salmon/sushi(-)', 'salmon teriaki rice',\n",
       "       'jinro cham yi sul (fresh)(standard)', 'fried egg(-)',\n",
       "       'beef teriyaki(-)', 'chilli beef(standard)',\n",
       "       'bento korean fried wings(-)', 'green tea(-)',\n",
       "       'restaurant match day special(standard)', 'fanta(standard)',\n",
       "       'lunch set(-)', 'fried chicken wings (4pc)(standard)',\n",
       "       'restaurant special set (seafood pancake)(-)',\n",
       "       'chicken teriyaki 红烧鸡肉(-)', 'soup ramen(pork belly)',\n",
       "       'sashimi (4pc)(salmon)', 'tiger(standard)',\n",
       "       'beef bulgogi(standard)', 'beef teriyaki(standard)',\n",
       "       'miso soup(standard)', 'cheesy toppoki(-)',\n",
       "       'hai tai bong bong grape juice(standard)',\n",
       "       'spicy chicken katsu(standard)', 'veg okonomiyaki(-)',\n",
       "       'tsing tao(standard)', 'restaurant plum sour(standard)',\n",
       "       'poke bowl no avocado(-)', 'navy rum(single)',\n",
       "       'chilli lobster firecracker rice(-)', 'fried egg on yaki soba(-)',\n",
       "       'takoyaki(standard)', 'j2o(standard)', 'koppaberg(standard)',\n",
       "       'ta box and bag(-)', 'baby guinness', 'prawn tempura rice (-)',\n",
       "       'kimchi fried rice(pork)', 'salmon teriaki', 'bag(-)',\n",
       "       'maki (3pc)(salmon)', 'soup ramen(chilli beef)',\n",
       "       'takeaway box and bag(-)', 'beef teriyaki rice(-)',\n",
       "       'chicken karaagi(standard)', '+ egg fried rice(-)',\n",
       "       'nigiri (3pc)(salmon)', 'dash cordial(-)', 'soup ramen(chicken)',\n",
       "       'mochi(-)', 'dorayaki(-)', 'sambuca(single)', 'pork hotpot(-)',\n",
       "       'dolsot bimbimbap(beef)', 'beef curry(standard)', 'cocktaill(-)',\n",
       "       'small sake(-)', 'gordans(single)', 'pork yakitori(standard)',\n",
       "       'mojito(passion fruit)', 'bulgogi(standard)',\n",
       "       'gordans pink gin(single)', 'kimchi(standard)',\n",
       "       'dolsot bimbimbap beef & chicken(-)', 'dynamite(standard)',\n",
       "       'gordans(double)', 'becks blue(standard)', 'bento kfc & pb(-)',\n",
       "       'prawn katsu curry(standard)', 'takeaway(-)',\n",
       "       'teriyaki salmon(standard)', 'lettuce(-)', 'coke zero',\n",
       "       'cornish orchard cider(pint)', 'peroni(half)',\n",
       "       'ice cream(default)', 'still / sparkling water(330ml)',\n",
       "       'yuk gae jang(standard)', 'edamame(standard)',\n",
       "       'maki (3pc)(cucumber)', 'still / sparkling water(750ml)',\n",
       "       'lunch/early set', 'soda water(standard)',\n",
       "       'maki (3pc)(chicken katsu)', 'fudge cake(-)',\n",
       "       'soft shell crab tempura(standard)', 'california(standard)',\n",
       "       'pork bulgogi 猪肉片饭(-)', 'ja jang myun(standard)',\n",
       "       'korean set menu(standard)', 'restaurant set(-)',\n",
       "       'kirin ichi ban(standard)', 'salmon teriyaki 照烧三文鱼(-)', 'cocktail',\n",
       "       'bento chicken harumaki(4pc)(-)', 'wasabi prawns(standard)',\n",
       "       'bento mandu/c.c.curry(-)', 'tapokki with cheese (-)',\n",
       "       'spicy lamb noodle(-)', 'americano(-)',\n",
       "       'belvino pinot grigio rosato(250ml)', 'kan pun ki(-)',\n",
       "       'additional beef(-)', 'tofu(-)', 'chili prawn firecracker rice(-)',\n",
       "       'box (-)', 'monte verde sauvignon blanc(250ml)',\n",
       "       'kimchi fried rice(chicken)', 'teriyaki chicken(standard)',\n",
       "       'yaki soba(vegatable)', 'grilled unagi(default)',\n",
       "       'seared salmon roll(-)', 'korean yoghurt soju(standard)',\n",
       "       'dolsot bimbimbap(chicken)', 'maki (6pc)(salmon)',\n",
       "       'kimchi set(standard)', 'burger(-)', 'pork bulgogi(default)',\n",
       "       'yaki udon(chicken)', 'double espresso(-)', 'yaki soba(beef)',\n",
       "       'kimchi ramen(standard)', 'apple juice(standard)',\n",
       "       'prawn cracker(-)', 'tap water(jug)', 'kimchi pancake(standard)',\n",
       "       'plain noodles(-)', 'asahi(-)',\n",
       "       'pinot grigio san vigilio provincia di pavia igt(bottle)',\n",
       "       'bento vegetable tempura(-)', 'monte verde merlot(175ml)',\n",
       "       'beef teriyaki bun(standard)', 'bento chicken katsu sushi(4pc)(-)',\n",
       "       'agedashi tofu(standard)', 'seafood pancake(standard)',\n",
       "       'salmon sashimi (4pc)(salmon)', 'egg rice bento(-)',\n",
       "       'lettuce, garlic & chilli(standard)', 'restaurant buns platter',\n",
       "       'maki (3pc)(avocado)', 'takeaway box', 'squid thop bap(standard)',\n",
       "       'baileys(single)', 'kan pun ki (6pc)(standard)',\n",
       "       'topokki(standard)', 'spicy mixed seafood noodles han',\n",
       "       'smirnoff(double)', 'boxes(-)', 'ginger ale (-)',\n",
       "       'monte verde sauvignon blanc(bottle)', 'ebi katsu roll(8pc)',\n",
       "       'sunrise(passion fruit)', 'bossam pork belly(standard)',\n",
       "       'yaki soba(chicken katsu)', 'pan fried scallops(-)',\n",
       "       'tonkatsu curry(standard)', 'smirnoff(single)', 'tonic(standard)',\n",
       "       'pork belly(standard)', 'maki (6pc)(chicken katsu)',\n",
       "       'japanese slipper(standard)', 'parini pinot grigio(250ml)',\n",
       "       'da luca prosecco(standard)', 'duck sushi roll(-)',\n",
       "       'berri estates shiraz(175ml)', 'parini pinot grigio(175ml)',\n",
       "       'cheesecake(standard)', 'yaki udon(vegetable)',\n",
       "       'hotpot with chicken(-)', 'half peroni(-)', 'latte(standard)',\n",
       "       'tea(standard)', 'aubergine donburi(-)', 'matcha mojito(standard)',\n",
       "       'salmon teriaki with udon(-)', 'yaki udon(beef)',\n",
       "       'sauvignon blanc brisa(175ml)', 'test(-)',\n",
       "       'sho set/seafood pancake starter first(-)', 'corona(standard)',\n",
       "       'orange juice(standard)', 'espresso martini', 'takeaway boxes(-)',\n",
       "       'kagugiri 6pc(-)', 'sake(default)',\n",
       "       'spicy salmon poke bowl/miso  soup(-)',\n",
       "       'monte verde sauvignon blanc(175ml)', 'cheese(-)',\n",
       "       'dolsot bimbimbap(pork)', 'sunny side up egg(-)',\n",
       "       'berri estates shiraz(250ml)', 'chicken bulgogi(default)',\n",
       "       'spf(-)', 'mandu / chix teriyaki bento egg fried rice(-)',\n",
       "       'restaurant special pancake seafood(-)',\n",
       "       'salmon maki cj breaktime hehez ty(-)', 'maki (6pc)(cucumber)',\n",
       "       'yaki soba with tofu(-)', 'chicken teriyaki bun(standard)',\n",
       "       'kimchi stew(standard)', 'grill wings(standard)',\n",
       "       'grilled squid(standard)', 'grill meat platter(standard)',\n",
       "       'singha lager(half)', 'yaki soba (-)',\n",
       "       'salmon teriyaki yaki soba(-)', 'spicy tuna(standard)',\n",
       "       'tofu curry(-)', 'katsudon pork(standard)',\n",
       "       'tentojidon ricebowl(-)', 'espresso(standard)', 'magical lagoon',\n",
       "       'yaki soba(seafood)', 'king prawn(standard)',\n",
       "       'kagugiri (sushi rolls 4pc)(standard)',\n",
       "       'tebaski chicken wings(standard)', 'chicken hotpot(-)',\n",
       "       'rum(single)', 'sprite', 'yaki udon(chicken katsu)',\n",
       "       'maki (6pc)(avocado)', 'pineapple juice(standard)',\n",
       "       'ribeye add on(-)', 'juice(orange 🍊)',\n",
       "       'restaurant special set seafood pancake(-)', 'ginza roll(-)',\n",
       "       'extra duck buns(-)', 'hotpot beef(-)', 'yaki udon(seafood)',\n",
       "       'salmon teriyaki(standard)', 'fever tree slimline tonic(standard)',\n",
       "       'yaki udon(king prawns)', 'egg fried rice add(-)',\n",
       "       'duck roll(4pc)', 'restaurant special set/sesfood pancake(-)',\n",
       "       'gimbap(vegetable)', 'soft shell crab(standard)',\n",
       "       'bok gum bap mixed with chix and prawns(-)',\n",
       "       'temaki (1pc)(salmon)', 'miso lamb(standard)',\n",
       "       'chicken katsu(standard)', 'parini pinot grigio(bottle)',\n",
       "       'soup vegetable(-)', 'monte verde merlot(250ml)',\n",
       "       'salmon tartar(standard)', 'restaurant  set menu(-)',\n",
       "       'for cherry’s “sake”', 'long island iced tea', 'california(4pc)',\n",
       "       'cucumber kimchi(standard)', 'dynamite(4pc)',\n",
       "       'tofu stew(standard)', 'kimchi fried rice(vegetable)',\n",
       "       'grill meat platter(-)',\n",
       "       'restaurant special set/seafood pancake(-)', 'dynamite(8pc)',\n",
       "       'restaurant set for 2 (-)', 'shirley temple',\n",
       "       'teriyaki salmon side(standard)', 'tofu katsu small plate(-)',\n",
       "       'cheesy topokki(-)', 'sauvignon blanc brisa(250ml)',\n",
       "       'mojito(cherry 🍒)', 'calpis(standard)', 'tequila bottle(-)',\n",
       "       'jinro cham yi sul (green grapes)(standard)', 'whiskey(double)',\n",
       "       'restaurant special(-)', 'gluten free tofu(-)', 'soju plum(-)',\n",
       "       'dolsot bimbimbap(vegetable)', 'sunrise(mango)',\n",
       "       'short mile bay chardonnay(250ml)',\n",
       "       'restaurant set/seafood pancake starter first(-)',\n",
       "       'small plain yaki soba(-)', 'teriyaki beef(standard)',\n",
       "       'kagugiri(standard)', 'dwaeji galbi ribs(default)',\n",
       "       'yaki udon with ribeye(-)', 'belvino pinot grigio rosato(175ml)',\n",
       "       'kkori gom tang(standard)', 'soup ramen(seafood)',\n",
       "       'bento /slicy salmon poke bowl(-)',\n",
       "       'gewurztraminer a.a.c. cave de beblenheim(175ml)',\n",
       "       'rare vineyards pinot noir(bottle)',\n",
       "       'nigiri platter (12pc)(standard)', 'juice(apple 🍎)', 'egg(-)',\n",
       "       'hot pot with pork(-)', 'gordans pink gin(double)',\n",
       "       'juice(mango 🥭)', 'salmon avocado(standard)', 'ginger ale',\n",
       "       'soup ramen(grilled ribeye steak)', 'cornish cider(-)',\n",
       "       'carrier bag(-)', 'juice(standard)', 'milk(-)', 'soju(plum)',\n",
       "       'nigiri (3pc)(eel)', 'yaki soba(chicken katsu curry)',\n",
       "       'tofu katsu bun(standard)', 'alma mora malbec(250ml)', 'f.egg(-)',\n",
       "       'seafood okonomiyaki(standard)',\n",
       "       'cullinan view chenin blanc(250ml)', 'tea(green)', 'x(-)',\n",
       "       'cappuccino(standard)', 'gimbap(spicy chicken)',\n",
       "       'spicy chicken katsu(4pc)', 'bento lunch set 1(-)',\n",
       "       'tuna tartar(standard)', 'teriyaki chicken side(standard)',\n",
       "       'grilled unagi eel(standard)',\n",
       "       'salmon & tobiko eggfried rice(standard)', 'nigiri (3pc)(prawn)',\n",
       "       'pumpkin curry(-)', 'soup udon(chicken)',\n",
       "       'parini pinot grigio(125ml)',\n",
       "       'belvino pinot grigio rosato(bottle)', 'gimbap(chicken)',\n",
       "       'beef teriyaki with egg fried rice(-)', 'whispering hills(bottle)',\n",
       "       'extra cheese(-)', 'lunch set miso/tentojidon(-)',\n",
       "       'california(8pc)', 'bok gum bap(pork)', 'gimbap(pork belly)',\n",
       "       'soup ramen(pork cutlet katsu)', 'sushi platter (30pc)(standard)',\n",
       "       'restaurant set/seafood pancake(-)', 'melon liqueur',\n",
       "       'chicken katsu curry with egg fried rice(-)',\n",
       "       'monte verde sauvignon blanc(125ml)', 'mooli kimchi(standard)',\n",
       "       'ginger ale(-)', 'yaki soba(king prawns)',\n",
       "       'whispering hills(125ml)', 'salmon sashimi & tobiko(standard)',\n",
       "       'smoked salmon roll(-)', 'vine trail gewurztraminer(125ml)',\n",
       "       'soup udon(pork belly)', 'katsu sauce (-)',\n",
       "       'slimline tonic(standard)', 'bok gum bap(chicken)',\n",
       "       'corn cheese(standard)', 'whispering hills(175ml)',\n",
       "       'spicy fried rice(-)', 'green soju(-)', 'maki (3pc)(tuna)',\n",
       "       'king prawns (5pc)(standard)', 'soju(-)',\n",
       "       'short mile bay chardonnay(175ml)',\n",
       "       'pinot grigio san vigilio provincia di pavia igt(250ml)',\n",
       "       'cornish orchard cider(half)', 'alma mora malbec(bottle)',\n",
       "       'monte verde merlot(bottle)',\n",
       "       'pinot grigio san vigilio provincia di pavia igt(175ml)',\n",
       "       'chargrilled squid(standard)', 'egg fried rice (-)',\n",
       "       'beef jap chae(standard)', 'whispering hills(250ml)',\n",
       "       'bombay(double)', 'noodlees(-)', 'ramen(-)',\n",
       "       'yaki udon with rib eye steak - medium(-)',\n",
       "       'restaurant special / kimchi pancake(-)', 'jack daniels(double)',\n",
       "       'tofu kimchi(standard)', 'stella(half)',\n",
       "       'japanese grill platter(standard)', 'lychee liqueur', 'boxx(-)',\n",
       "       'temaki (1pc)(prawn tempura)', 'dips(-)', 'tea(jasmine green)',\n",
       "       'soju(green grape🍇)', 'pan seared seabass(standard)',\n",
       "       'sette bello prosecco(20cl)', 'grilled unagi rice(default)',\n",
       "       'nigiri (3pc)(prawn tempura)', 'smoked salmon roll(4pc)',\n",
       "       'margarita', 'mojito(lychee)', 'extra ramen(-)',\n",
       "       'pinot grigio blush delle venezie igt san vigil(175ml)',\n",
       "       'half singha(half)', 'jack daniels(single)',\n",
       "       'seafood platter(standard)', 'miso aubergine small plate(-)',\n",
       "       'chilli lobster rice(-)',\n",
       "       'hot pot with beef  add ons: 1 noodle, cheese and s(-)',\n",
       "       'rare vineyards pinot noir(175ml)',\n",
       "       'yaki udon(grilled ribeye steak)', 'extra pork belly(-)',\n",
       "       'berri estates shiraz(bottle)', 'ebi katsu roll(4pc)',\n",
       "       'soup ramen(vegetable)', 'sashimi (4pc)(tuna)',\n",
       "       'short mile bay chardonnay(bottle)', 'miso lamb (4pc)(standard)',\n",
       "       'pinot grigio blush delle venezie igt san vigil(250ml)',\n",
       "       'soup udon(chilli beef)', 'yaki soba(grilled ribeye steak)',\n",
       "       'salmon poke bowl(-)', 'nigiri (3pc)(tuna)',\n",
       "       'bok gum bap(vegetable)', 'ice(-)',\n",
       "       'fever tree pink tonic(standard)', 'ox tongue(standard)',\n",
       "       'yaki udon(pan seared duck)', 'ginza roll(4pc)',\n",
       "       'sake(white wine)', 'gimbap(beef)', 'temaki (1pc)(chicken katsu)',\n",
       "       'vine trail gewurztraminer(bottle)',\n",
       "       'rare vineyards pinot noir(250ml)',\n",
       "       'pinot grigio san vigilio provincia di pavia igt(125ml)',\n",
       "       'bombay(single)', 'soup ramen vegetable no noodles(-)',\n",
       "       'white zinfandel burlesque(250ml)',\n",
       "       'sauvignon blanc brisa(bottle)', 'avocado salad(-)',\n",
       "       'crispy pata(-)',\n",
       "       'dolsot bimbimbap with vegetables and egg fried ric(-)',\n",
       "       'beef teriyaki (egg fried rice instead)(-)',\n",
       "       'merlot valle central brisa(250ml)',\n",
       "       'pulpo sauvignon blanc(250ml)',\n",
       "       'malbec la nina mendoza don cristobal(250ml)', 'extra chicken(-)',\n",
       "       'chargrilled rib eye steak(standard)', 'juice(pineapple 🍍)',\n",
       "       'whisky smash', 'temaki (1pc)(avocado)',\n",
       "       'pan seared duck breast(standard)', 'soup udon(seafood)',\n",
       "       'nigiri (3pc)(avocado)', 'soba veg(-)', 'summer rosé spritz',\n",
       "       'whiskey(single)', 'pinot noir pays d’oc igp le fou(250ml)',\n",
       "       'vine trail gewurztraminer(175ml)', 'cannapi(-)',\n",
       "       'beef teriyaki buns (3 buns)(-)',\n",
       "       'merlot valle central brisa(175ml)', 'alma mora malbec(175ml)',\n",
       "       'tungkol sayoooo~~(-)', 'additional pork belly(-)',\n",
       "       'pancit canton(-)', 'tea(english)', 'tentojidon & miso soup(-)',\n",
       "       'baileys(double)', 'tonic(-)', 'pumpkin katsu small plate(-)',\n",
       "       'mixed vegetable(standard)', 'plain soba noodles(-)',\n",
       "       'spicy chicken katsu(8pc)',\n",
       "       'buns platter ( beef, chicken, duck)(-)',\n",
       "       'add on egg fried rice(-)',\n",
       "       'chenin blanc slow false bay coastal region(250ml)',\n",
       "       'bellini(mango 🥭)', 'amaretto(single)', 'rainbow roll(4pc)',\n",
       "       'chicken(-)', 'temaki (1pc)(tuna)', 'seared salmon roll(4pc)',\n",
       "       'soup ramen vegetable with vegetable broth non (-)',\n",
       "       'belvino pinot grigio rosato(125ml)', 'prosecco lunetta(bottle)',\n",
       "       'pinot grigio blush delle venezie igt san vigil(bottle)',\n",
       "       'cullinan view chenin blanc(125ml)', 'yaki soba(pan seared duck)',\n",
       "       'fruit tea(-)', 'vine trail gewurztraminer(250ml)',\n",
       "       'da luca rosato spumante(standard)',\n",
       "       'cullinan view chenin blanc(175ml)',\n",
       "       'sauvignon blanc brisa(125ml)', 'd. egg(standard)',\n",
       "       'camden pale ale(half)', 'vegetable ramen with vegetable broth(-)',\n",
       "       'duck roll(8pc)', 'malbec la nina mendoza don cristobal(bottle)',\n",
       "       'veg sushi platter(-)', 'restaurant special set (-)',\n",
       "       'gunkan 2pc(avocado)', 'monte verde merlot(125ml)',\n",
       "       'wakame salad(standard)', 'chardonnay woolloomooloo(250ml)',\n",
       "       'malibu(-)', 'cullinan view chenin blanc(bottle)',\n",
       "       'dubu jorim(standard)', 'white zinfandel burlesque(bottle)',\n",
       "       'soup ramen', 'gimbap(pork)',\n",
       "       'restaurant special set\\\\ seafood pancake(-)', 'passion killer',\n",
       "       'sette bello prosecco(bottle)', 'plain noddles(-)',\n",
       "       'passoã collins', 'sambuca(double)',\n",
       "       'short mile bay chardonnay(125ml)', 'rare tuna(standard)',\n",
       "       'curry sauce dips(-)', 'soup udon(vegetable)',\n",
       "       'soup udon(king prawns)',\n",
       "       'gewurztraminer a.a.c. cave de beblenheim(bottle)',\n",
       "       'vegetable skewer 杂菜串(-)', 'grilled unagi eel side(standard)',\n",
       "       'big order takeaway(-)', 'baileys bottle(-)',\n",
       "       'maki (3pc)(bell pepper)', 'soup udon(pork katsu)',\n",
       "       'cosmopolitan(-)', 'cranberry juice(-)', 'soup ramen(king prawns)',\n",
       "       'bento box (chicken harumaki / chix teriyaki / egg (-)',\n",
       "       'bag and box(-)', 'merlot valle central brisa(125ml)',\n",
       "       'white zinfandel burlesque(175ml)', 'alma mora malbec(125ml)',\n",
       "       'taittinger brut reserve nv(standard)', 'other(-)',\n",
       "       'fried rice(-)', 'soup udon(grilled ribeye steak)',\n",
       "       'soft shell crab 8pc(standard)', 'amaretto(double)', 'rum(double)',\n",
       "       'soju(fresh)', 'shiraz woolloomooloo(250ml)',\n",
       "       'tentojidon rice bowl(-)', 'prosecco lunetta(20cl)',\n",
       "       'seared salmon roll(8pc)', 'salmon avocado(8pc)',\n",
       "       'kimchee fried rice(chicken)', 'berri estates shiraz(125ml)',\n",
       "       'mojito(standard)', 'merlot valle central brisa(bottle)',\n",
       "       'soup ramen(beef)',\n",
       "       'gewurztraminer a.a.c. cave de beblenheim(250ml)', 'tentojidon(-)',\n",
       "       'hot chocolate(-)', 'egg f.rice(-)',\n",
       "       'chardonnay woolloomooloo(125ml)', 't\\\\a box(-)',\n",
       "       'salmon avocado(4pc)', 'pulpo sauvignon blanc(125ml)',\n",
       "       'brandy(double)', 'korean restaurant set (seafood pancake)(-)',\n",
       "       'tea(peppermint)', 'half portion of yaki soba chicken(-)',\n",
       "       'chardonnay woolloomooloo(bottle)',\n",
       "       'pinot noir pays d’oc igp le fou(bottle)',\n",
       "       'rare vineyards pinot noir(125ml)', 'nigiri (3pc)(tamago)',\n",
       "       'gunkan 2pc(spicy tuna)', 'shiraz woolloomooloo(bottle)',\n",
       "       'nigiri (3pc)(seared salmon)', 'yuk gae jang with tofu (-)',\n",
       "       'chenin blanc slow false bay coastal region(175ml)',\n",
       "       'korean set menu(-)', 'udon noodles(-)',\n",
       "       'chardonnay woolloomooloo(175ml)', 'juice(cranberry)',\n",
       "       'navy rum(double)', 'soup udon', 'gunkan 2pc(dynamite)',\n",
       "       'martell(single)', 'restaurant special seafood pancake(-)',\n",
       "       'restaurant set/kimchi pancake(-)', 'shiraz woolloomooloo(175ml)',\n",
       "       'salmon poke bown/both gf(-)', 'tataki(salmon salsa)',\n",
       "       'liquer coffee(-)', 'sunrise', 'egg fried rice upgrade(-)',\n",
       "       'maki (6pc)(bell pepper)', 'nigiri (3pc)(beef)', 'ginza roll(8pc)',\n",
       "       'pulpo sauvignon blanc(bottle)', 'rainbow roll(8pc)',\n",
       "       'taittinger prestige brut rose(standard)',\n",
       "       'korean restaurant special set(-)', 'diced avocado(-)',\n",
       "       'pulpo sauvignon blanc(175ml)',\n",
       "       'pinot noir pays d’oc igp le fou(175ml)', 'hot pot(seafood)',\n",
       "       'beef(-)', 'prawn katsu curry with egg rice(-)',\n",
       "       'hendricks(double)', 'nigiri (3pc)(asparagus)',\n",
       "       'salmon sashimi(standard)', 'bellini(lychee)',\n",
       "       'nigiri (3pc)(inari)', 'bellini(passion fruit)', 'soju(standard)',\n",
       "       'eel dragon roll(4pc)', 'pan fried cod fillet(standard)',\n",
       "       'pancit canton seafood(-)',\n",
       "       'pinot grigio blush delle venezie igt san vigil(125ml)',\n",
       "       'lunetta vino spumante rose brut(bottle)',\n",
       "       'malbec la nina mendoza don cristobal(175ml)', 'extra egg(-)',\n",
       "       'white zinfandel burlesque(125ml)',\n",
       "       'chenin blanc slow false bay coastal region(125ml)',\n",
       "       'bento ( avo maki & pumpkin curry)(-)', 'eel dragon roll(8pc)',\n",
       "       'smoked salmon roll(8pc)', 'chicken noodles(-)',\n",
       "       'veg sushi platter 20pc(-)',\n",
       "       'restaurant soft shell crab rolls(standard)', 'd. espresso(-)',\n",
       "       'passoa', 'pork belly(-)', 'extra boiled eggs(-)',\n",
       "       'shiraz woolloomooloo(125ml)',\n",
       "       'lunetta vino spumante rose brut(20cl)',\n",
       "       'chenin blanc slow false bay coastal region(bottle)',\n",
       "       'fish karaage(-)', 'rainbow roll(standard)',\n",
       "       'kimchee fried rice(vegetable)', 'seared salmon nigiri',\n",
       "       'salmon poke bowl (-)', 'jinro cham yi sul(green grape🍇)',\n",
       "       'jinro cham yi sul(standard)', 'tofu katsu with rice (-)',\n",
       "       'chicken katsu maki (4pc)(standard)', 'umi zarigani(standard)',\n",
       "       'tonkatsu(-)', 'malbec la nina mendoza don cristobal(125ml)',\n",
       "       'spicy chicken gimbap(-)', 'tofu teriyaki buns(-)', 'efr(-)',\n",
       "       'dessert(standard)', 'tataki(beef tataki)', 'duck roll(standard)',\n",
       "       'egg fried rice on beef teriyaki(-)', 'becks blue(-)',\n",
       "       'prawn tempura nigiri replacement(-)',\n",
       "       'gunkan (2pc)(spicy tuna or spicy salmon)', 'beef teriyaki (-)',\n",
       "       'hotpot ~ beef(-)', 'dissarano(-)',\n",
       "       'pinot noir pays d’oc igp le fou(125ml)', 'egg fried ricee(-)',\n",
       "       'plain ramen noodles(-)',\n",
       "       'restaurant buns platter (3x ducks / 3x chix teriyaki)(-)',\n",
       "       'steamed milk(-)', 'kimchi fried rice beef(-)', 'prawns(-)',\n",
       "       'extra prawns(-)', 'tufo(-)', 'additional vegetable(-)',\n",
       "       'hotpot add-on(sliced beef)',\n",
       "       'extra fried egg on kimchi for table2(-)', 'plain soba(-)',\n",
       "       'kimchi fried rice', 'hotpot seafood(-)', 'hot pot(beef)',\n",
       "       'hot pot(pork)', 'hotpot add-on(sliced pork 🥓)',\n",
       "       'kimchee fried rice(seafood)', 'eel dragon roll(standard)',\n",
       "       'vegetable raman little spicy(-)', 'toppoki(-)', 'brandy(single)',\n",
       "       'sushi platter (16 pc)(standard)',\n",
       "       'gewurztraminer a.a.c. cave de beblenheim(125ml)',\n",
       "       'cocumber kimchi(-)', 'chopped chillies(-)', 'chablis 250ml(-)',\n",
       "       'boiled egg(-)', 'noodles(-)', 'soup noodles spicy(-)',\n",
       "       'salmon teriyaki egg fried rice (-)', 'flowers(-)',\n",
       "       'gunkan (2pc)(avacado)'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>sold</th>\n",
       "      <th>sales_inc_tax</th>\n",
       "      <th>discount</th>\n",
       "      <th>sales_exc_tax</th>\n",
       "      <th>cost_inc_tax</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cocktail(-)</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>37</td>\n",
       "      <td>259.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>2022-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>cocktail(-)</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>36</td>\n",
       "      <td>252.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>2022-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>cocktail(-)</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>34</td>\n",
       "      <td>238.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2022-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>cocktail(-)</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>30</td>\n",
       "      <td>209.30</td>\n",
       "      <td>0.7</td>\n",
       "      <td>209.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>209.3</td>\n",
       "      <td>2022-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>cocktail(-)</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>30</td>\n",
       "      <td>210.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>2022-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86841</th>\n",
       "      <td>restaurant plum sour(standard)</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>1</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2022-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86900</th>\n",
       "      <td>matcha mojito(standard)</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>1</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2022-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86945</th>\n",
       "      <td>cocktail(-)</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>1</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2022-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87012</th>\n",
       "      <td>asia daisy(standard)</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>1</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2023-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87055</th>\n",
       "      <td>cocktail(-)</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>1</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2023-12-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2934 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name   category  sold  sales_inc_tax  \\\n",
       "47                        cocktail(-)  cocktails    37         259.00   \n",
       "49                        cocktail(-)  cocktails    36         252.00   \n",
       "60                        cocktail(-)  cocktails    34         238.00   \n",
       "85                        cocktail(-)  cocktails    30         209.30   \n",
       "86                        cocktail(-)  cocktails    30         210.00   \n",
       "...                               ...        ...   ...            ...   \n",
       "86841  restaurant plum sour(standard)  cocktails     1           6.67   \n",
       "86900         matcha mojito(standard)  cocktails     1           6.67   \n",
       "86945                     cocktail(-)  cocktails     1           7.00   \n",
       "87012            asia daisy(standard)  cocktails     1           6.67   \n",
       "87055                     cocktail(-)  cocktails     1           7.00   \n",
       "\n",
       "       discount  sales_exc_tax  cost_inc_tax  gross_profit        date  \n",
       "47          0.0          259.0           0.0         259.0  2022-06-18  \n",
       "49          0.0          252.0           0.0         252.0  2022-02-26  \n",
       "60          0.0          238.0           0.0         238.0  2022-01-22  \n",
       "85          0.7          209.3           0.0         209.3  2022-07-15  \n",
       "86          0.0          210.0           0.0         210.0  2022-01-29  \n",
       "...         ...            ...           ...           ...         ...  \n",
       "86841       0.0            7.0           0.0           7.0  2022-01-04  \n",
       "86900       0.0            7.0           0.0           7.0  2022-09-15  \n",
       "86945       0.0            7.0           0.0           7.0  2022-01-04  \n",
       "87012       0.0            7.0           0.0           7.0  2023-07-20  \n",
       "87055       0.0            7.0           0.0           7.0  2023-12-11  \n",
       "\n",
       "[2934 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.category.str.lower().str.contains(\"cocktail\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting `variant` from the products. Fortunately, variant is easily found. \n",
    "\n",
    "Each name is in the form `product name(variant)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87055</th>\n",
       "      <td>cocktail</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87056</th>\n",
       "      <td>sweet potato fries</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87057</th>\n",
       "      <td>dolsot bimbimbap</td>\n",
       "      <td>beef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87058</th>\n",
       "      <td>kimchi fried rice</td>\n",
       "      <td>pork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87059</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name variant\n",
       "87055            cocktail       -\n",
       "87056  sweet potato fries       -\n",
       "87057    dolsot bimbimbap    beef\n",
       "87058   kimchi fried rice    pork\n",
       "87059                 NaN     NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = df.name.str.extract(\"(?P<name>.+)\\((?P<variant>.+)\\)\")\n",
    "product.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some names still have `(...)` in their names but this is fine as they are part of the name itself and not a variant of the product.\n",
    "\n",
    "We can see below that it's all `name (#pc)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>mandu (5pc)</td>\n",
       "      <td>standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>mandu (5pc)</td>\n",
       "      <td>standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>mandu (5pc)</td>\n",
       "      <td>standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>bento mandu dumplings(4pc)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>mandu (5pc)</td>\n",
       "      <td>standard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name   variant\n",
       "148                 mandu (5pc)  standard\n",
       "280                 mandu (5pc)  standard\n",
       "553                 mandu (5pc)  standard\n",
       "679  bento mandu dumplings(4pc)         -\n",
       "683                 mandu (5pc)  standard"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product[product.name.str.contains(\"\\(.+\\)\", regex=True).fillna(False)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some products also do not have their variants encoded in their original names as they don't have any variants. This leads to their `name` and `variant` value being `NaN` when performing `pandas.extract`. \n",
    "\n",
    "We can see this below from their original `name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>sold</th>\n",
       "      <th>sales_inc_tax</th>\n",
       "      <th>discount</th>\n",
       "      <th>sales_exc_tax</th>\n",
       "      <th>cost_inc_tax</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>restaurant special set</td>\n",
       "      <td>restaurant special</td>\n",
       "      <td>19</td>\n",
       "      <td>541.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>568.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>568.1</td>\n",
       "      <td>2023-10-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>crispy duck bun</td>\n",
       "      <td>buns 24-28</td>\n",
       "      <td>15</td>\n",
       "      <td>112.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.5</td>\n",
       "      <td>2023-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>crispy duck bun</td>\n",
       "      <td>buns 24-28</td>\n",
       "      <td>15</td>\n",
       "      <td>112.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.5</td>\n",
       "      <td>2023-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>crispy duck bun</td>\n",
       "      <td>buns 33-38</td>\n",
       "      <td>14</td>\n",
       "      <td>118.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.6</td>\n",
       "      <td>2024-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>singha lager</td>\n",
       "      <td>draught beer</td>\n",
       "      <td>14</td>\n",
       "      <td>72.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.8</td>\n",
       "      <td>2023-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name            category  sold  sales_inc_tax  \\\n",
       "366  restaurant special set  restaurant special    19         541.05   \n",
       "647         crispy duck bun          buns 24-28    15         112.86   \n",
       "652         crispy duck bun          buns 24-28    15         112.86   \n",
       "773         crispy duck bun          buns 33-38    14         118.67   \n",
       "861            singha lager        draught beer    14          72.80   \n",
       "\n",
       "     discount  sales_exc_tax  cost_inc_tax  gross_profit        date  \n",
       "366       0.0          568.1           0.0         568.1  2023-10-21  \n",
       "647       0.0          118.5           0.0         118.5  2023-09-30  \n",
       "652       0.0          118.5           0.0         118.5  2023-02-17  \n",
       "773       0.0          124.6           0.0         124.6  2024-03-16  \n",
       "861       0.0           72.8           0.0          72.8  2023-07-21  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[product.name.isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate `name` and `variant` using the extracted values\n",
    "\n",
    "Make sure to only populate `name` with non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chicken katsu curry</td>\n",
       "      <td>standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tap water</td>\n",
       "      <td>glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>peroni</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>asahi</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name   variant\n",
       "0                 asahi      pint\n",
       "1                 asahi      pint\n",
       "2                 asahi      pint\n",
       "3                 asahi      pint\n",
       "4                 asahi      pint\n",
       "5   chicken katsu curry  standard\n",
       "6                 asahi      pint\n",
       "7                 asahi      pint\n",
       "8             tap water     glass\n",
       "9                 asahi      pint\n",
       "10                asahi      pint\n",
       "11                asahi      pint\n",
       "12                asahi      pint\n",
       "13                asahi      pint\n",
       "14                asahi      pint\n",
       "15                asahi      pint\n",
       "16                asahi      pint\n",
       "17               peroni      pint\n",
       "18                asahi      pint\n",
       "19                asahi      pint"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"variant\"] = product.variant\n",
    "df.loc[product[product.name.notna()].index, \"name\"] = product[product.name.notna()].name\n",
    "df[[\"name\", \"variant\"]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unifying Names and Categories\n",
    "\n",
    "The most time consuming by far in this dataset is the correction of product names and categories.\n",
    "It will require some manual work but I will try to do majority of the work with pandas.\n",
    "\n",
    "My main strategy is going to use a technique called [approximate string matching](https://en.wikipedia.org/wiki/Approximate_string_matching) also called as fuzzy string matching to find names that are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['draught beer', 'donburi 29-39', 'soft drinks', 'cocktails',\n",
       "       'korean starter 53-61', 'donburi 29-38', 'sides', 'custom',\n",
       "       'sides extras', 'japan rice dis 25-32', 'restaurant special',\n",
       "       'spirits', 'traditional 1-14', 'buns 24-28', 'traditional 1-15',\n",
       "       'lunch bento', 'noodles 47-48', 'buns 25-26',\n",
       "       'bottled beer & cider', 'buns 33-38', 'bbq (korean) 75 - 84',\n",
       "       'korean soft drinks', 'japanese side 1-13', 'korean soju',\n",
       "       'korean side 14-24', 'tea / coffee', 'special mains 39-46',\n",
       "       'sushi', 'set menu', 'sushi rolls (4pc)', 'vegan',\n",
       "       'ramen & noodle 39-40', 'spirits & shots', 'rice dishes 70-74',\n",
       "       'dessert', 'white wine', 'robata grill 15-23',\n",
       "       'korean dishes 41-51', 'asian cocktails', 'korean sides 49-52',\n",
       "       'robata grill 16-24', 'soup 66-69', 'korean nood 62-64',\n",
       "       'korean set menu', 'classic cocktails', 'korean nood 62-65',\n",
       "       'rose wine', 'red wine', 'other', 'restaurant grill bbq 52-60',\n",
       "       'sushi rolls 4pc/8pc', 'mocktails', 'champagne', 'platters 45-46',\n",
       "       'restaurant specials', 'sushi platters', 'platters 27-28',\n",
       "       'bbq platters 59-60', 'extras', 'new items', 'hotpot',\n",
       "       'seared salmon nigiri'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asahi', 'chicken katsu curry', 'tap water', 'peroni', 'cocktail',\n",
       "       'coke', 'stella', 'diet coke', 'mandu (5pc)', 'chilli fries',\n",
       "       'pan seared seabass', 'camden pale ale',\n",
       "       'ramen pork belly w/extra veg', 'lemonade', 'drinks',\n",
       "       'takeaway box', 'egg fried rice', 'mocktail',\n",
       "       'restaurant special set', 'tequila', 'steamed rice',\n",
       "       'prawn tempura', 'trial', 'box', 'asia daisy', 'crispy duck bun',\n",
       "       'bento mandu dumplings(4pc)', 'yaki soba', 'chicken teriyaki',\n",
       "       'lucky buddha', 'container', 'fever tree tonic',\n",
       "       'kimchi fried rice chix and pork', 'chicken harumaki', 'rib eye',\n",
       "       'chicken katsu  curry 日式咖喱鸡', 'singha lager', 'aloe vera',\n",
       "       'chicken katsu bun', 'spicy squid', 'sweet potato fries',\n",
       "       'restaurant special set with seafood pancake', 'vegetable tempura',\n",
       "       'duck harumaki', 'yaki soba vegetable 1/2 portion', 'corona',\n",
       "       'bento salmon/sushi', 'salmon teriaki rice',\n",
       "       'jinro cham yi sul (fresh)', 'fried egg', 'beef teriyaki',\n",
       "       'chilli beef', 'bento korean fried wings', 'green tea',\n",
       "       'restaurant match day special', 'fanta', 'lunch set',\n",
       "       'fried chicken wings (4pc)',\n",
       "       'restaurant special set (seafood pancake)',\n",
       "       'chicken teriyaki 红烧鸡肉', 'soup ramen', 'sashimi (4pc)', 'tiger',\n",
       "       'beef bulgogi', 'miso soup', 'cheesy toppoki',\n",
       "       'hai tai bong bong grape juice', 'spicy chicken katsu',\n",
       "       'veg okonomiyaki', 'tsing tao', 'restaurant plum sour',\n",
       "       'poke bowl no avocado', 'navy rum',\n",
       "       'chilli lobster firecracker rice', 'fried egg on yaki soba',\n",
       "       'takoyaki', 'j2o', 'koppaberg', 'ta box and bag', 'baby guinness',\n",
       "       'prawn tempura rice ', 'kimchi fried rice', 'salmon teriaki',\n",
       "       'bag', 'maki (3pc)', 'takeaway box and bag', 'beef teriyaki rice',\n",
       "       'chicken karaagi', '+ egg fried rice', 'nigiri (3pc)',\n",
       "       'dash cordial', 'mochi', 'dorayaki', 'sambuca', 'pork hotpot',\n",
       "       'dolsot bimbimbap', 'beef curry', 'cocktaill', 'small sake',\n",
       "       'gordans', 'pork yakitori', 'mojito', 'bulgogi',\n",
       "       'gordans pink gin', 'kimchi', 'dolsot bimbimbap beef & chicken',\n",
       "       'dynamite', 'becks blue', 'bento kfc & pb', 'prawn katsu curry',\n",
       "       'takeaway', 'teriyaki salmon', 'lettuce', 'coke zero',\n",
       "       'cornish orchard cider', 'ice cream', 'still / sparkling water',\n",
       "       'yuk gae jang', 'edamame', 'lunch/early set', 'soda water',\n",
       "       'fudge cake', 'soft shell crab tempura', 'california',\n",
       "       'pork bulgogi 猪肉片饭', 'ja jang myun', 'korean set menu',\n",
       "       'restaurant set', 'kirin ichi ban', 'salmon teriyaki 照烧三文鱼',\n",
       "       'bento chicken harumaki(4pc)', 'wasabi prawns',\n",
       "       'bento mandu/c.c.curry', 'tapokki with cheese ',\n",
       "       'spicy lamb noodle', 'americano', 'belvino pinot grigio rosato',\n",
       "       'kan pun ki', 'additional beef', 'tofu',\n",
       "       'chili prawn firecracker rice', 'box ',\n",
       "       'monte verde sauvignon blanc', 'teriyaki chicken', 'grilled unagi',\n",
       "       'seared salmon roll', 'korean yoghurt soju', 'maki (6pc)',\n",
       "       'kimchi set', 'burger', 'pork bulgogi', 'yaki udon',\n",
       "       'double espresso', 'kimchi ramen', 'apple juice', 'prawn cracker',\n",
       "       'kimchi pancake', 'plain noodles',\n",
       "       'pinot grigio san vigilio provincia di pavia igt',\n",
       "       'bento vegetable tempura', 'monte verde merlot',\n",
       "       'beef teriyaki bun', 'bento chicken katsu sushi(4pc)',\n",
       "       'agedashi tofu', 'seafood pancake', 'salmon sashimi (4pc)',\n",
       "       'egg rice bento', 'lettuce, garlic & chilli',\n",
       "       'restaurant buns platter', 'squid thop bap', 'baileys',\n",
       "       'kan pun ki (6pc)', 'topokki', 'spicy mixed seafood noodles han',\n",
       "       'smirnoff', 'boxes', 'ginger ale ', 'ebi katsu roll', 'sunrise',\n",
       "       'bossam pork belly', 'pan fried scallops', 'tonkatsu curry',\n",
       "       'tonic', 'pork belly', 'japanese slipper', 'parini pinot grigio',\n",
       "       'da luca prosecco', 'duck sushi roll', 'berri estates shiraz',\n",
       "       'cheesecake', 'hotpot with chicken', 'half peroni', 'latte', 'tea',\n",
       "       'aubergine donburi', 'matcha mojito', 'salmon teriaki with udon',\n",
       "       'sauvignon blanc brisa', 'test',\n",
       "       'sho set/seafood pancake starter first', 'orange juice',\n",
       "       'espresso martini', 'takeaway boxes', 'kagugiri 6pc', 'sake',\n",
       "       'spicy salmon poke bowl/miso  soup', 'cheese', 'sunny side up egg',\n",
       "       'chicken bulgogi', 'spf',\n",
       "       'mandu / chix teriyaki bento egg fried rice',\n",
       "       'restaurant special pancake seafood',\n",
       "       'salmon maki cj breaktime hehez ty', 'yaki soba with tofu',\n",
       "       'chicken teriyaki bun', 'kimchi stew', 'grill wings',\n",
       "       'grilled squid', 'grill meat platter', 'yaki soba ',\n",
       "       'salmon teriyaki yaki soba', 'spicy tuna', 'tofu curry',\n",
       "       'katsudon pork', 'tentojidon ricebowl', 'espresso',\n",
       "       'magical lagoon', 'king prawn', 'kagugiri (sushi rolls 4pc)',\n",
       "       'tebaski chicken wings', 'chicken hotpot', 'rum', 'sprite',\n",
       "       'pineapple juice', 'ribeye add on', 'juice',\n",
       "       'restaurant special set seafood pancake', 'ginza roll',\n",
       "       'extra duck buns', 'hotpot beef', 'salmon teriyaki',\n",
       "       'fever tree slimline tonic', 'egg fried rice add', 'duck roll',\n",
       "       'restaurant special set/sesfood pancake', 'gimbap',\n",
       "       'soft shell crab', 'bok gum bap mixed with chix and prawns',\n",
       "       'temaki (1pc)', 'miso lamb', 'chicken katsu', 'soup vegetable',\n",
       "       'salmon tartar', 'restaurant  set menu', 'for cherry’s “sake”',\n",
       "       'long island iced tea', 'cucumber kimchi', 'tofu stew',\n",
       "       'restaurant special set/seafood pancake', 'restaurant set for 2 ',\n",
       "       'shirley temple', 'teriyaki salmon side', 'tofu katsu small plate',\n",
       "       'cheesy topokki', 'calpis', 'tequila bottle',\n",
       "       'jinro cham yi sul (green grapes)', 'whiskey',\n",
       "       'restaurant special', 'gluten free tofu', 'soju plum',\n",
       "       'short mile bay chardonnay',\n",
       "       'restaurant set/seafood pancake starter first',\n",
       "       'small plain yaki soba', 'teriyaki beef', 'kagugiri',\n",
       "       'dwaeji galbi ribs', 'yaki udon with ribeye', 'kkori gom tang',\n",
       "       'bento /slicy salmon poke bowl',\n",
       "       'gewurztraminer a.a.c. cave de beblenheim',\n",
       "       'rare vineyards pinot noir', 'nigiri platter (12pc)', 'egg',\n",
       "       'hot pot with pork', 'salmon avocado', 'ginger ale',\n",
       "       'cornish cider', 'carrier bag', 'milk', 'soju', 'tofu katsu bun',\n",
       "       'alma mora malbec', 'f.egg', 'seafood okonomiyaki',\n",
       "       'cullinan view chenin blanc', 'x', 'cappuccino',\n",
       "       'bento lunch set 1', 'tuna tartar', 'teriyaki chicken side',\n",
       "       'grilled unagi eel', 'salmon & tobiko eggfried rice',\n",
       "       'pumpkin curry', 'soup udon', 'beef teriyaki with egg fried rice',\n",
       "       'whispering hills', 'extra cheese', 'lunch set miso/tentojidon',\n",
       "       'bok gum bap', 'sushi platter (30pc)',\n",
       "       'restaurant set/seafood pancake', 'melon liqueur',\n",
       "       'chicken katsu curry with egg fried rice', 'mooli kimchi',\n",
       "       'salmon sashimi & tobiko', 'smoked salmon roll',\n",
       "       'vine trail gewurztraminer', 'katsu sauce ', 'slimline tonic',\n",
       "       'corn cheese', 'spicy fried rice', 'green soju',\n",
       "       'king prawns (5pc)', 'chargrilled squid', 'egg fried rice ',\n",
       "       'beef jap chae', 'bombay', 'noodlees', 'ramen',\n",
       "       'yaki udon with rib eye steak - medium',\n",
       "       'restaurant special / kimchi pancake', 'jack daniels',\n",
       "       'tofu kimchi', 'japanese grill platter', 'lychee liqueur', 'boxx',\n",
       "       'dips', 'sette bello prosecco', 'grilled unagi rice', 'margarita',\n",
       "       'extra ramen', 'pinot grigio blush delle venezie igt san vigil',\n",
       "       'half singha', 'seafood platter', 'miso aubergine small plate',\n",
       "       'chilli lobster rice',\n",
       "       'hot pot with beef  add ons: 1 noodle, cheese and s',\n",
       "       'extra pork belly', 'miso lamb (4pc)', 'salmon poke bowl', 'ice',\n",
       "       'fever tree pink tonic', 'ox tongue',\n",
       "       'soup ramen vegetable no noodles', 'white zinfandel burlesque',\n",
       "       'avocado salad', 'crispy pata',\n",
       "       'dolsot bimbimbap with vegetables and egg fried ric',\n",
       "       'beef teriyaki (egg fried rice instead)',\n",
       "       'merlot valle central brisa', 'pulpo sauvignon blanc',\n",
       "       'malbec la nina mendoza don cristobal', 'extra chicken',\n",
       "       'chargrilled rib eye steak', 'whisky smash',\n",
       "       'pan seared duck breast', 'soba veg', 'summer rosé spritz',\n",
       "       'pinot noir pays d’oc igp le fou', 'cannapi',\n",
       "       'beef teriyaki buns (3 buns)', 'tungkol sayoooo~~',\n",
       "       'additional pork belly', 'pancit canton', 'tentojidon & miso soup',\n",
       "       'pumpkin katsu small plate', 'mixed vegetable',\n",
       "       'plain soba noodles', 'buns platter ( beef, chicken, duck)',\n",
       "       'add on egg fried rice',\n",
       "       'chenin blanc slow false bay coastal region', 'bellini',\n",
       "       'amaretto', 'rainbow roll', 'chicken',\n",
       "       'soup ramen vegetable with vegetable broth non ',\n",
       "       'prosecco lunetta', 'fruit tea', 'da luca rosato spumante',\n",
       "       'd. egg', 'vegetable ramen with vegetable broth',\n",
       "       'veg sushi platter', 'restaurant special set ', 'gunkan 2pc',\n",
       "       'wakame salad', 'chardonnay woolloomooloo', 'malibu', 'dubu jorim',\n",
       "       'restaurant special set\\\\ seafood pancake', 'passion killer',\n",
       "       'plain noddles', 'passoã collins', 'rare tuna', 'curry sauce dips',\n",
       "       'vegetable skewer 杂菜串', 'grilled unagi eel side',\n",
       "       'big order takeaway', 'baileys bottle', 'cosmopolitan',\n",
       "       'cranberry juice',\n",
       "       'bento box (chicken harumaki / chix teriyaki / egg ',\n",
       "       'bag and box', 'taittinger brut reserve nv', 'other', 'fried rice',\n",
       "       'soft shell crab 8pc', 'shiraz woolloomooloo',\n",
       "       'tentojidon rice bowl', 'kimchee fried rice', 'tentojidon',\n",
       "       'hot chocolate', 'egg f.rice', 't\\\\a box', 'brandy',\n",
       "       'korean restaurant set (seafood pancake)',\n",
       "       'half portion of yaki soba chicken', 'yuk gae jang with tofu ',\n",
       "       'udon noodles', 'martell', 'restaurant special seafood pancake',\n",
       "       'restaurant set/kimchi pancake', 'salmon poke bown/both gf',\n",
       "       'tataki', 'liquer coffee', 'egg fried rice upgrade',\n",
       "       'taittinger prestige brut rose', 'korean restaurant special set',\n",
       "       'diced avocado', 'hot pot', 'beef',\n",
       "       'prawn katsu curry with egg rice', 'hendricks', 'salmon sashimi',\n",
       "       'eel dragon roll', 'pan fried cod fillet', 'pancit canton seafood',\n",
       "       'lunetta vino spumante rose brut', 'extra egg',\n",
       "       'bento ( avo maki & pumpkin curry)', 'chicken noodles',\n",
       "       'veg sushi platter 20pc', 'restaurant soft shell crab rolls',\n",
       "       'd. espresso', 'passoa', 'extra boiled eggs', 'fish karaage',\n",
       "       'seared salmon nigiri', 'salmon poke bowl ', 'jinro cham yi sul',\n",
       "       'tofu katsu with rice ', 'chicken katsu maki (4pc)',\n",
       "       'umi zarigani', 'tonkatsu', 'spicy chicken gimbap',\n",
       "       'tofu teriyaki buns', 'efr', 'dessert',\n",
       "       'egg fried rice on beef teriyaki',\n",
       "       'prawn tempura nigiri replacement', 'gunkan (2pc)',\n",
       "       'beef teriyaki ', 'hotpot ~ beef', 'dissarano', 'egg fried ricee',\n",
       "       'plain ramen noodles',\n",
       "       'restaurant buns platter (3x ducks / 3x chix teriyaki)',\n",
       "       'steamed milk', 'kimchi fried rice beef', 'prawns', 'extra prawns',\n",
       "       'tufo', 'additional vegetable', 'hotpot add-on',\n",
       "       'extra fried egg on kimchi for table2', 'plain soba',\n",
       "       'hotpot seafood', 'vegetable raman little spicy', 'toppoki',\n",
       "       'sushi platter (16 pc)', 'cocumber kimchi', 'chopped chillies',\n",
       "       'chablis 250ml', 'boiled egg', 'noodles', 'soup noodles spicy',\n",
       "       'salmon teriyaki egg fried rice ', 'flowers'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz, process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove numbers and noise from name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>sold</th>\n",
       "      <th>sales_inc_tax</th>\n",
       "      <th>discount</th>\n",
       "      <th>sales_exc_tax</th>\n",
       "      <th>cost_inc_tax</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>date</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87055</th>\n",
       "      <td>cocktail</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>1</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87056</th>\n",
       "      <td>sweet potato fries</td>\n",
       "      <td>sides extras</td>\n",
       "      <td>1</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87057</th>\n",
       "      <td>dolsot bimbimbap</td>\n",
       "      <td>korean dishes 41-51</td>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>beef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87058</th>\n",
       "      <td>kimchi fried rice</td>\n",
       "      <td>korean dishes 41-51</td>\n",
       "      <td>1</td>\n",
       "      <td>12.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>pork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87059</th>\n",
       "      <td>restaurant buns platter</td>\n",
       "      <td>buns 24-28</td>\n",
       "      <td>1</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name             category  sold  sales_inc_tax  \\\n",
       "87055                 cocktail            cocktails     1           7.00   \n",
       "87056       sweet potato fries         sides extras     1           3.33   \n",
       "87057         dolsot bimbimbap  korean dishes 41-51     1          13.24   \n",
       "87058        kimchi fried rice  korean dishes 41-51     1          12.29   \n",
       "87059  restaurant buns platter           buns 24-28     1          18.00   \n",
       "\n",
       "       discount  sales_exc_tax  cost_inc_tax  gross_profit        date variant  \n",
       "87055       0.0            7.0           0.0           7.0  2023-12-11       -  \n",
       "87056       0.0            3.5           0.0           3.5  2023-12-11       -  \n",
       "87057       0.0           13.9           0.0          13.9  2023-12-11    beef  \n",
       "87058       0.0           12.9           0.0          12.9  2023-12-11    pork  \n",
       "87059       0.0           18.9           0.0          18.9  2022-11-19     NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in [\"name\", \"category\"]:\n",
    "    df[col] = df[col].str.replace(\"\\(.+\\)\", \"\", regex=True)\n",
    "    df[col] = df[col].str.replace(\"^(\\d{1,2}\\.?)\\s*\", \"\", regex=True)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove numbers from category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['draught beer', 'donburi', 'soft drinks', 'cocktails',\n",
       "       'korean starter', 'sides', 'custom', 'sides extras',\n",
       "       'japan rice dis', 'restaurant special', 'spirits', 'traditional',\n",
       "       'buns', 'lunch bento', 'noodles', 'bottled beer & cider', 'bbq',\n",
       "       'korean soft drinks', 'japanese side', 'korean soju',\n",
       "       'korean side', 'tea / coffee', 'special mains', 'sushi',\n",
       "       'set menu', 'sushi rolls', 'vegan', 'ramen & noodle',\n",
       "       'spirits & shots', 'rice dishes', 'dessert', 'white wine',\n",
       "       'robata grill', 'korean dishes', 'asian cocktails', 'korean sides',\n",
       "       'soup', 'korean nood', 'korean set menu', 'classic cocktails',\n",
       "       'rose wine', 'red wine', 'other', 'restaurant grill bbq',\n",
       "       'sushi rolls 4pc/8pc', 'mocktails', 'champagne', 'platters',\n",
       "       'restaurant specials', 'sushi platters', 'bbq platters', 'extras',\n",
       "       'new items', 'hotpot', 'seared salmon nigiri'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category = df.category.str.replace(\"\\d{1,2}\\s?\\-\\s?\\d{1,2}\", \"\", regex=True)\n",
    "df.category = df.category.str.strip()\n",
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"custom\",\n",
    "    \"asian cocktail\",\n",
    "    \"cocktail\",\n",
    "    \"draught beer\",\n",
    "    \"\"\n",
    "    \"traditional\",\n",
    "    \"starters\",\n",
    "    \"sides\",\n",
    "    \"donburi\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sushi rolls</td>\n",
       "      <td>95</td>\n",
       "      <td>1548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sushi rolls</td>\n",
       "      <td>95</td>\n",
       "      <td>2299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sushi rolls</td>\n",
       "      <td>95</td>\n",
       "      <td>2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sushi rolls</td>\n",
       "      <td>95</td>\n",
       "      <td>2552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sushi rolls</td>\n",
       "      <td>95</td>\n",
       "      <td>2607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>sushi rolls</td>\n",
       "      <td>95</td>\n",
       "      <td>7108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>sushi rolls</td>\n",
       "      <td>95</td>\n",
       "      <td>7138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>sushi rolls</td>\n",
       "      <td>95</td>\n",
       "      <td>7140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sushi rolls</td>\n",
       "      <td>95</td>\n",
       "      <td>7141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>sushi rolls</td>\n",
       "      <td>95</td>\n",
       "      <td>7257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0   1     2\n",
       "0   sushi rolls  95  1548\n",
       "1   sushi rolls  95  2299\n",
       "2   sushi rolls  95  2302\n",
       "3   sushi rolls  95  2552\n",
       "4   sushi rolls  95  2607\n",
       "..          ...  ..   ...\n",
       "95  sushi rolls  95  7108\n",
       "96  sushi rolls  95  7138\n",
       "97  sushi rolls  95  7140\n",
       "98  sushi rolls  95  7141\n",
       "99  sushi rolls  95  7257\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(process.extract(\"sushi roll\", df.category, limit=100))#[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>sold</th>\n",
       "      <th>sales_inc_tax</th>\n",
       "      <th>discount</th>\n",
       "      <th>sales_exc_tax</th>\n",
       "      <th>cost_inc_tax</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>date</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asahi</td>\n",
       "      <td>draught beer</td>\n",
       "      <td>82</td>\n",
       "      <td>406.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>426.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426.40</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asahi</td>\n",
       "      <td>draught beer</td>\n",
       "      <td>64</td>\n",
       "      <td>316.46</td>\n",
       "      <td>0.52</td>\n",
       "      <td>332.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332.28</td>\n",
       "      <td>2022-10-08</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asahi</td>\n",
       "      <td>draught beer</td>\n",
       "      <td>63</td>\n",
       "      <td>312.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>327.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327.60</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asahi</td>\n",
       "      <td>draught beer</td>\n",
       "      <td>63</td>\n",
       "      <td>312.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>327.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327.60</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asahi</td>\n",
       "      <td>draught beer</td>\n",
       "      <td>62</td>\n",
       "      <td>306.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>321.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>321.88</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>pint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name      category  sold  sales_inc_tax  discount  sales_exc_tax  \\\n",
       "0  asahi  draught beer    82         406.10      0.00         426.40   \n",
       "1  asahi  draught beer    64         316.46      0.52         332.28   \n",
       "2  asahi  draught beer    63         312.00      0.00         327.60   \n",
       "3  asahi  draught beer    63         312.00      0.00         327.60   \n",
       "4  asahi  draught beer    62         306.55      0.52         321.88   \n",
       "\n",
       "   cost_inc_tax  gross_profit        date variant  \n",
       "0           0.0        426.40  2022-11-12    pint  \n",
       "1           0.0        332.28  2022-10-08    pint  \n",
       "2           0.0        327.60  2023-01-10    pint  \n",
       "3           0.0        327.60  2023-11-25    pint  \n",
       "4           0.0        321.88  2022-05-21    pint  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
